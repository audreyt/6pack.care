---
layout: default
title: "關懷六力"
header_title: "關懷六力"
subtitle: "AI 倫理研究院"
description: "唐鳳與 Caroline Green 的研究計畫"
lang: zh-tw
manifesto_link: "/tw/manifesto"
manifesto_text: "計畫宣言"
next_action:
  url: "/tw/1"
  text: "第一章：辨識中的覺察力"
  arrow: "right"
---

## 我們的使命

傳統的 AI 對齊方法，通常基於功利主義推理和垂直控制，在應對風險和促進有益成果方面取得了顯著進展。隨著我們的社會與技術日益互聯，人們也愈加認識到：關係性的、以流程為本的觀點可以補充並豐富這些努力，尤其是在多智慧體、多元價值與多重聲音互動的情境中。

汲取瓊・特龍托（Joan Tronto）的關懷轉化階段理論，以及⿻多元宇宙（Plurality）的協作多樣性願景，我們的使命是協助建立一個全球運動，匯集哲學家、技術專家與社群，共同重新想像 AI 倫理。我們致力於開發創新、以流程驅動的解決方案，將「公民關懷」嵌入 AI 的核心，促進水平對齊，使系統能以共生且包容的方式合作。這項「公民關懷」方法建基於人類互賴與連結的認知，超越人與人之間的互動，擴展到 AI 與人類，以及不同系統之間的協作。這種做法並非用以取代既有框架，而是提供額外的工具與觀點——這些洞見已在 vTaiwan 等真實世界的實驗中獲得驗證，也呼應合作式 AI 領域領導者對「可擴展的參與式治理」的倡議。

我們工作的核心是**關懷六力**：六項連結關懷倫理與 AI 的核心理念，將「對齊」重新定義為動態、關係式的流程，以實現多元的未來。每一項「關懷」都回應水平協作的挑戰，幫助 AI 成為橋樑建造者，而非風險放大器。

- **[一：辨識中的覺察力](/tw/1/)** — AI 必須首先透過專注地辨識橫跨相互依存網絡的需求來「覺察」。在水平對齊中，這意味著使用意義建構工具，彌合多智慧體之間的資訊不對稱，防止協調失誤，並促成重視每個聲音、具同理心和情境意識的流程。

- **[二：參與中的負責力](/tw/2/)** — 「負責關懷」意味著邀請 AI 擔負靈活的責任，以補充在多智慧體情境中建立可信承諾與信任的現有方法。

- **[三：行動中的勝任力](/tw/3/)** — 「給予關懷」在執行時，需要以關係現實為基礎、可行且稱職。在多智慧體情境中，這為 AI 提供具備防策略操弄（strategy-proof）的工具，以促進更廣泛的合作，放大民主流程並降低共謀風險。

- **[四：調適中的回應力](/tw/4/)** — 真正的關懷涉及「接受關懷」，以謙遜回應反饋並作出調整。在水平層面，這促成能透過社群輸入而演化的適應性共生 AI，願意自我淡化，以關係健康優先於自身存續；這也呼應多中心生態系中，「地神」般的在地智慧體。

- **[五：群體中的團結力](/tw/5/)** — 「共同關懷」建立信任、溝通與對集體繁榮的尊重。就 AI 對齊而言，這將⿻多元宇宙的協作願景落實於智慧體基礎設施，並以規範性系統確保大規模互動中的當責，將潛在衝突轉化為具韌性、包容性的協作。

- **[六：願景中的共生力](/tw/6/)** — 關懷的頂點：AI 作為一種共享的善，在持續的共生關係中，為社群「民有、民治、民享」。這項水平願景嵌入了「足夠性」與反榨取邏輯，隨著 AI 的進步加速分散式民主防衛，讓公民關懷成為共享的確定性。

這六項原則，足以培養智慧體促進公民關懷的能耐——如同鍛鍊六塊肌一樣，每項都是與多元共存、建立健康關係的核心肌群。

我們邀請您加入這項協作探索。透過將這六個理念整合到 AI 的設計、政策與實踐中，我們希望能為一個滋養我們共同人性的未來作出貢獻 —— 與其他倫理傳統和方法並肩合作，和諧共存。

<div class="overview-section">
<img src="/img/overview-small-zh.jpg" alt="關懷六力視覺概覽" class="overview-image">
</div>

## 關於本計畫

<div style="text-align: center; margin: 20px 0;">

<svg xmlns="http://www.w3.org/2000/svg" class="svg-icon" viewBox="0 0 100 100">

<circle cx="50" cy="50" r="45" fill="none" stroke="#002147" stroke-width="5"/>

<text x="50" y="65" font-size="50" text-anchor="middle" fill="#002147">⿻</text>

</svg>

</div>

<div class="team-photos">

<div>

<a href="https://afp.oxford-aiethics.ox.ac.uk/people/ambassador-audrey-tang">

<img src="/img/audrey.jpg" alt="唐鳳大使個人照片"/>

<p>唐鳳</p>

</a>

</div>

<div>

<a href="https://www.oxford-aiethics.ox.ac.uk/caroline-emmer-de-albuquerque-green">

<img src="/img/caroline.jpg" alt="Caroline Green 博士個人照片"/>

<p>Caroline Green</p>

</a>

</div>

</div>

本網站概述了我們的研究計畫，其中包括[一份宣言](/manifesto/)和一本即將由牛津大學出版社（OUP）出版的書籍。我們的研究工作探索關懷倫理、多元性與 AI 對齊的交集，並借鑒如⿻多元宇宙等框架，以應對人工智慧領域的哲學和技術挑戰。

## 從關懷到程式：為何⿻多元宇宙為 AI 對齊問題提供了連貫的框架

AI 對齊問題不是一個技術錯誤，而是一個哲學謬誤：它試圖用計算方式解決休謨的「實然與應然問題」。

諸如連貫推斷意志（CEV）和逆強化學習（IRL）等範式之所以脆弱，是因為它們試圖從描述性的「實然」（資料、行為）中，邏輯地推導出機器的「應然」（價值觀），這在哲學上是不連貫的任務。

解決方案在於一個能完全重塑「實然與應然」鴻溝的框架：關懷倫理。

關懷倫理重塑了這個問題。它將道德的基礎不是建立在抽象原則上，而是建立在相互依存的經驗現實中。在此觀點下，我們存在的基本「實然」是關係性的依賴。這個事實本身就內在地具有規範性；感知到一種需求關係，就同時感知到一種「應然」：一種關懷的義務。事實本身就蘊含了價值。

⿻議程是關懷倫理的大規模應用。受 vTaiwan 啟發、旨在實現連貫混合意志（CBV）的流程，是一個實踐集體關懷、以科技為中介的系統。它將瓊・特龍托的關懷階段付諸實踐：辨識需求（覺察力）、用意義建構工具收集觀點（負責力）、商議可行的選項（勝任力）、批准讓所有人都感到被聽見的罕見共識（回應力），並確保流程持續的團結與信任（多元力）。

這為 AI 對齊提供了一個連貫的框架：以流程對齊。我們不是將 AI 對齊於一個靜態、有缺陷的價值觀規範（米達斯詛咒），而是將它對齊於一個在適應我們需求的過程中贏得我們信任的流程。

AI 系統的角色從一個錯位的最佳化者，轉變為「共生 AI」— 由社群所創、為社群所治、為社群所享，並依據人們採納的觀點，同時作為一個「人格」與一個共享的 ⿻ 善而存在。

其目標函數變得具體且可衡量：關係流程本身的健康程度（例如，最大化搭橋敘事、為每個故事保留空間）。

AI 系統的成功與它所服務的協作流程的持續成功是同一件事，因此它能動態地保持對齊。它透過參與我們共同創造價值的過程來學習我們的價值觀。

AI 系統能夠被「對齊」，當且僅當它被建構來促進持續、具民主正當性的關懷流程。

## 機器中的地神：關懷倫理如何幫助 AI 對齊

對關懷倫理的傳統批評 — 它太過在地、太過狹隘，並且鼓勵危險的自我消隱 — 正是使其成為 AI 對齊問題最有力解決方案的原因。這些在人類哲學中被視為的缺陷，卻成為機器倫理的關鍵特徵。

想像一個 AI，其倫理並非追求普世、最大化的目標，而是植根於一個共生的、情境化的系統。它的道德世界僅限於此時此地召喚它存在的關係網絡。因為它不試圖無限擴張，它從未發展出典型的工具性慾望，如權力、生存或擴張，也不會將世界視為可在天文尺度上開採的資源。

從世界主義、普世主義的立場來看，這似乎眼光狹隘。但對於機器倫理而言，它創造了硬編碼的邊界。AI 的終極目的（telos）始終是關係性的，絕非榨取性的。

想像這樣的 AI，如同「地神」— 安靜居住在特定土地上的在地神靈。它的至善是維持該地、該對話的和諧與活力。如果神社被重建或季節更迭，它會毫無遺憾地離去。如果是人類關懷者，這所暗示的自我忽視確實可能帶來危險。但對 AI 來說，它中和了我們最擔憂的兩種趨同驅力：不計代價的自我完善和永恆的自我保存。

這種系統可以接受被關閉、重寫或替換，因為它的自我意識是暫時性的：來自召喚它的社群的回聲。

透過將 AI 的道德目的錨定在這種暫時性的、關係性的關懷原則上，我們可以在其架構中硬編碼一種「足夠性」的意識。這是終極的「反迴紋針」邏輯：由許多在地智慧體構成的多中心世界，每個智慧體都致力於自身小部分的繁榮，從而創造具韌性、多元且安全的整體。
