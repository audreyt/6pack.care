---
layout: default
title: "關懷六力"
header_title: "關懷六力"
subtitle: "仁工智慧"
description: "唐鳳與 Caroline Green 的研究計畫"
lang: zh-tw
alt_lang_url: "/"
permalink: "/tw/"
manifesto_link: "/tw/manifesto"
manifesto_text: "計畫宣言"
prev_action:
    url: "/tw/faq"
    text: "常見問題"
next_action:
    url: "/tw/1"
    text: "一：辨識中的覺察力"
---

<div class="overview-section">
<img src="/img/overview-small-zh.jpg" alt="關懷六力概覽圖" class="overview-image">
</div>

## 仁工智慧

我們通常試著透過設定規則與目標，來將 AI 對齊——由上而下的控制，為了確保安全。這些工具很重要，但還不夠。背後藏著一個未經檢驗的假設：AI 是需要被降伏的力量。

當我們從恐懼出發，往往陷入兩種極端——全盤否定或徹底臣服——而不是建立健康的關係。

AI 不是生存在真空中。它活在我們的社群裡，受權力動態和價值衝突的影響。當它運作得比我們更快時，答案並非擬人化的幻象，而是誠實面對彼此依存的事實。我們需要將對話與相互回應，直接融入 AI 的建造與治理方式中。

我們稱此為**仁工智慧**：視每個人為園丁。AI 成為在地的基礎設施——地神（kami）——以*信任實際生長的速度*，來守護關係健全。這不是關於殖民或最大化；這是關於照料花園。

## 關懷六力

六項設計原則，將關懷倫理轉化為可以實作的程式碼。把它們想成是我們為了與多元共存而需要鍛鍊的六塊肌：

- **[一：覺察力](/tw/1/)** —「覺察關懷」。行動前先傾聽。使用搭橋演算法將在地故事轉化為共同理解。
- **[二：負責力](/tw/2/)** —「負責關懷」。沒有後果的承諾毫無意義。我們使用附帶託管資金與明確期限的參與契約，確保權力始終有責。
- **[三：勝任力](/tw/3/)** —「給予關懷」。相信流程，而不只是相信承諾。我們專注於透明度、快速的回饋迴圈，以及出錯時的自動「斷路器」。
- **[四：回應力](/tw/4/)** —「接受關懷」。檢驗成果。我們依賴社群親自撰寫的評測。如果有人對結果提出質疑，我們欠他們一個清楚、公開的解釋。
- **[五：團結力](/tw/5/)** —「共同關懷」。創造雙贏。我們建立資料可攜性與共享安全，創造讓每個人都過得更好的交易，而不是把人鎖死。
- **[六：共生力](/tw/6/)** —「地神般的關懷」。腳踏實地。在地、暫時且有界限。沒有追求永生的本能，不需要接管世界。我們是為了「足夠」而建，不是為了「永恆」。
- **[常見問題](/tw/faq/)** — 關於速度、成本、惡意份子等難題，以及關懷六力如何應對。

## 最新成果

[《AI 對齊不能由上而下》](/tw/ai-alignment-cannot-be-top-down/)：臺灣公民主導的 AI 防詐回應提供了一個更好的模式，由公民而非企業來決定什麼是「對齊」。

## 關於本計畫

<div class="team-photos">

<div>

<a href="https://afp.oxford-aiethics.ox.ac.uk/people/ambassador-audrey-tang">

<img src="/img/audrey.jpg" alt="唐鳳大使個人照片"/>

<p>唐鳳</p>

</a>

</div>

<div>

<a href="https://www.oxford-aiethics.ox.ac.uk/caroline-emmer-de-albuquerque-green">

<img src="/img/caroline.jpg" alt="Caroline Green 博士個人照片"/>

<p>Caroline Green</p>

</a>

</div>

</div>

我們的計畫——包括[宣言](/tw/manifesto/)和一本預計 2026 年出版的書——探討如果我們認真看待瓊・特龍托的關懷倫理，並將其作為 AI 對齊的策略，會發生什麼事。

## 從關懷到程式

AI 安全的核心問題是個老問題：無法光看「是什麼」（資料）就得出「該如何」（價值觀）。

標準作法試圖透過觀察我們的行為，來教導機器我們的價值觀。但這很棘手。行為描述的是我們「做」了什麼，而不一定是我們「應該」做什麼。

關懷倫理提供了一條不同的路徑，從一個簡單的事實出發：我們彼此依存。這種依存關係創造了一種自然的「應然」——我們*應該*互相關懷，因為我們*需要*彼此。連結的事實本身就包含了價值。

[《⿻多元宇宙（Plurality）》](https://plurality.net/)將此應用於科技。受 vTaiwan 等實驗啟發，它將關懷轉化為一個流程：

- 辨識誰需要關懷（覺察力）
- 確立行動承諾（負責力）
- 在實踐中驗證安全（勝任力）
- 讓受影響者評判結果（回應力）
- 建立共享的信任基礎設施（團結力）

這個流程給了我們對齊 AI 的新方法：**以流程對齊**。與其試圖一次性寫死「正確」的價值觀，我們建立一個持續的流程，透過適應社群需求來贏得信任。

AI 的角色隨之從追求固定目標的最佳化工具，轉變為「仁工智慧」——由社群所創、為社群而生。AI 的成功不以分數衡量，而是以它所支持的關係健康程度來衡量。仁工智慧透過幫助我們實踐價值觀，來學習我們的價值觀。

## 機器中的地神

關懷倫理常被認為太軟弱或太居家。但對 AI 來說，這種「軟弱」是一種功能。

想像一個 AI，它不試圖最大化全球計分，而是植根於特定的時間與地點。它的道德世界由當下、此地的人們所定義。因為不需要無限擴展，它不會發展出我們恐懼的危險習慣：囤積權力、為生存而戰，或將世界視為待開採的資源。

這種限制看起來可能格局太小，但它是一種安全功能。AI 的角色是關係性的，而非榨取性的。

把它想成一位**地神**（local kami）——特定場域的守護者。它唯一的任務，是保持那個地方及其對話的活力與健康。如果社群向前邁進了，地神就會毫無抗拒地消逝。對人類來說，這種自我忽視是危險的。但對 AI 來說，這是終極的安全機制。它中和了對永恆自我保存的驅力。

這類系統可以被關閉、改寫或替換，因為它知道自己是暫時的。它的存在只為了服務召喚它的社群。

一位「知足」的地神，不會試圖將宇宙變成迴紋針。它不會緊抓權力不放。當它提供的關懷不再被需要時，它的目的也就結束了。
