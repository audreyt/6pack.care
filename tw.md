---
layout: default
title: "關懷六力"
header_title: "關懷六力"
subtitle: "AI 倫理研究院"
description: "唐鳳與 Caroline Green 的研究計畫"
lang: zh-tw
manifesto_link: "/tw/manifesto"
manifesto_text: "計畫宣言"
next_action:
  url: "/tw/1"
  text: "一：辨識中的覺察力"
  arrow: "right"
---

<div class="overview-section">
<img src="/img/overview-small-zh.jpg" alt="關懷六力視覺概覽" class="overview-image">
</div>

## 問題

當 AI 的速度是我們的千倍，預設的軌跡很清楚：我們成了花園，AI 成了園丁——由上而下照料人類的智慧。在這種速度下，傳統倫理失效了。效益主義預測後果的速度，趕不上後果引發連鎖反應的速度。義務論無法對一個在我們監督之外詮釋規則的系統強加規則。我們需要一個正視這種不對稱、但拒絕這種角色分配的框架。

這個框架就是**公民關懷**——根植於瓊・特龍托（Joan Tronto）的關懷倫理，以及⿻多元宇宙（Plurality）的協作多樣性願景。核心理念：我們彼此才是園丁。AI 是在地的基礎設施——一方場域的守護者，一位***地神***——以*關懷實際生長的速度*來支撐關懷。不是殖民的力量，不是最大化的力量。

## 關懷六力

六項設計原則，將關懷倫理轉化為可供機器驗證的約束。如同鍛鍊六塊肌，每一項都是與多元共存的核心肌群：

- **[一：覺察力](/tw/1/)** —「覺察關懷」。以廣泛傾聽和搭橋演算法，將在地知識轉化為共同知識。先搭橋，再決策。
- **[二：負責力](/tw/2/)** —「負責關懷」。透過參與契約做出可信、可驗證的承諾，附帶託管資金、具名負責人與明確時程。不容許不受制衡的權力。
- **[三：勝任力](/tw/3/)** —「給予關懷」。檢核流程。不是「相信我們就對了」——而是透明度、快速的社群回饋、違規時自動觸發暫停。衡量「失利時的信任」。
- **[四：回應力](/tw/4/)** —「接受關懷」。檢核成果。社群自撰的評測、由受影響者設計的指標、質疑的權利。受到質疑時，把模糊之處講清楚並留下紀錄。
- **[五：團結力](/tw/5/)** —「共同關懷」。追求共贏。資料可攜、部分匿名、聯邦式信任與安全——讓各方都能受益，而非相互毀滅。讓正和賽局容易參與。
- **[六：共生力](/tw/6/)** —「地神般的關懷」。有界、在地、暫時性。沒有生存本能，沒有擴張驅力。聯邦制用於協調，輔助原則用於自治。為「足夠」而建，不為永恆而造。
- **[常見問題](/tw/faq/)** — 對本框架的嚴肅挑戰——速度、成本、規模、假等價、威權 AI——以及關懷六力如何回應。

## 最新

我們發表了[《AI 對齊不能由上而下》](/tw/ai-alignment-cannot-be-top-down/)。這篇實踐報告，說明了台灣公民主導的 AI 防詐措施，如何體現由人民共同掌舵的對齊。

## 關於本計畫

<div class="team-photos">

<div>

<a href="https://afp.oxford-aiethics.ox.ac.uk/people/ambassador-audrey-tang">

<img src="/img/audrey.jpg" alt="唐鳳大使個人照片"/>

<p>唐鳳</p>

</a>

</div>

<div>

<a href="https://www.oxford-aiethics.ox.ac.uk/caroline-emmer-de-albuquerque-green">

<img src="/img/caroline.jpg" alt="Caroline Green 博士個人照片"/>

<p>Caroline Green</p>

</a>

</div>

</div>

本站背後的計畫，包括一份[宣言](/tw/manifesto/)和一本預計 2026 年出版的書，追問一個問題：如果認真看待瓊・特龍托的關懷倫理與⿻多元宇宙議程，AI 對齊會變成什麼樣？

## 從關懷到程式：為何⿻多元宇宙為 AI 對齊問題提供了連貫的框架

AI 對齊問題不是一個技術缺陷，而是一個哲學謬誤：它試圖用計算方式解決休謨的「實然與應然問題」。

諸如連貫外推意志（CEV）和逆向強化學習（IRL）等範式之所以脆弱，是因為它們試圖從描述性的「實然」（資料、行為）中，邏輯地推導出機器的「應然」（價值觀），這在哲學上是不連貫的任務。

解決方案在於一個能完全重塑「實然與應然」鴻溝的框架：關懷倫理。

關懷倫理重新定義了這個問題。它並不以抽象原則為道德基礎，而是從相互依存的經驗現實出發。從這個觀點來看，我們存在的基本「實然」是關係性的依賴。這個事實本身，其內在就具有規範性；一旦意識到某種需求關係，就已經被召喚出一種「應然」的關懷義務。事實本身就蘊含了價值。

⿻多元宇宙議程，是關懷倫理的大規模應用，以技術為中介、實踐集體關懷的系統，其流程受 vTaiwan 啟發，旨在實現連貫融合意志（CBV）。它將瓊・特龍托的關懷階段付諸實踐：辨識需求（覺察力）、用意義建構工具收集觀點（負責力）、商議可行的選項（勝任力）、確立讓所有人都感到被聽見的罕見共識（回應力），並確保對流程的持續信任（團結力）。

這為 AI 對齊提供了一個連貫的框架：以流程實現對齊。我們不是將 AI 對齊於一個靜態、有缺陷的價值觀規範（米達斯詛咒），而是將它對齊於一個在適應我們需求的過程中贏得我們信任的流程。

AI 系統的角色，從只會盲目最佳化的工具，轉變為「共生 AI」— 由社群所創、為社群所治、為社群所享，又能根據視角不同，同時作為一個「人格」與一個共享的多元善而存在。

其目標函數變得具體且可衡量：關係流程本身的健康程度（例如，最大化搭橋敘事、為每個故事提供安放的空間）。

AI 系統的成功，與其所服務的協作流程的持續成功，兩者密不可分，因此它能動態地保持對齊。它透過參與我們共同創造價值的過程，來學習我們的價值觀。

因此，AI 系統唯有被建構來促進持續、具民主正當性的關懷流程時，才能真正實現「對齊」。

## 機器中的地神：關懷倫理如何幫助 AI 對齊

關懷倫理向來被嫌太居家、太狹隘、太自我犧牲。放到機器倫理裡，這些全是優點，不是缺點。

想像一個 AI，其倫理並非追求普世、最大化的目標，而是植根於一個共生的、情境化的系統。它的道德世界，僅限於此時此地召喚它存在的關係網絡。沒有無限擴張的驅力，那些工具性誘因——累積權力、不計代價地存續、把世界當作礦場——根本不會浮現。

普世主義者會說這太狹隘。但對機器倫理而言，它創造了硬編碼的邊界。AI 的終極目的（telos）始終是關係性的，絕非榨取性的。

想像這樣的 AI，如同「地神」——靜靜棲息於特定場域，只為維繫此地、此對話的和諧與生機。如果神社被重建或季節更迭，它會毫無遺憾地離去。如果是人類關懷者，這所暗示的自我忽視確實可能帶來危險。但對 AI 來說，它中和了我們最擔憂的兩種趨同驅力：不計代價的自我完善和永恆的自我保存。

這種系統可以接受被關閉、重寫或替換，因為它的自我意識並非固有，而是來自召喚它的社群的回聲。

透過將 AI 的道德目的錨定在這種暫時性的、關係性的關懷原則上，我們可以在其架構中硬編碼一種「知足」的意識。這是終極的「反迴紋針」（anti-paperclip）邏輯：在這個由眾多在地智慧體組成的多中心世界中，每個智慧體都專注於自身環境的繁榮，從而共同構築出具韌性、多元且安全的整體。
