---
layout: default
title: "關懷六力"
header_title: "關懷六力"
subtitle: "AI 倫理研究院"
description: "唐鳳與 Caroline Green 的研究計畫"
lang: zh-tw
alt_lang_url: "/"
permalink: "/tw/"
manifesto_link: "/tw/manifesto"
manifesto_text: "計畫宣言"
next_action:
    url: "/tw/1"
    text: "一：辨識中的覺察力"
    arrow: "right"
---

<div class="overview-section">
<img src="/img/overview-small-zh.jpg" alt="關懷六力視覺概覽" class="overview-image">
</div>

## 關係式對齊的理由

我們通常試著透過設定規則與目標來將 AI 對齊——這些由上而下的控制是為了確保安全。這些工具很重要，但還不夠。

AI 不是生存在真空中。它活在我們的社群裡，受權力動態和衝突價值觀的影響。當這些系統運作得比我們討論的速度還快時，我們需要的就不只是防護措施了。我們需要將相互依存、對話與相互回應，直接融入 AI 的建造與治理方式中。

我們稱此為**公民關懷**。結合關懷倫理與 [⿻多元宇宙（Plurality）運動](https://plurality.net/)，這個方法視我們每個人為園丁。AI 成為了在地的基礎設施——一種場所精神，一位**地神**（Kami）——以信任實際生長的速度來支持關懷。這不是關於殖民或最大化；這是關於照料花園。

## 關懷六力

這六項設計原則將關懷倫理轉化為我們可以編寫的程式碼。把它們想成是我們為了與多元共存而需要鍛鍊的六塊肌：

- **[一：覺察力](/tw/1/)** —「覺察關懷」。行動前先傾聽。使用搭橋演算法將在地故事轉化為共同理解。
- **[二：負責力](/tw/2/)** —「負責關懷」。沒有後果的承諾毫無意義。我們使用附帶託管資金與明確期限的互動合約，確保權力始終有責。
- **[三：勝任力](/tw/3/)** —「給予關懷」。相信流程，而不只是相信承諾。我們專注於透明度、快速的回饋迴圈，以及出錯時的自動「斷路器」。
- **[四：回應力](/tw/4/)** —「接受關懷」。檢驗成果。我們依賴社群親自撰寫的評測。如果有人對結果提出質疑，我們欠他們一個清楚、公開的解釋。
- **[五：團結力](/tw/5/)** —「共同關懷」。創造雙贏。我們建立資料可攜性與共享安全，創造讓每個人都過得更好的交易，而不是把人鎖死。
- **[六：共生力](/tw/6/)** —「地神般的關懷」。腳踏實地。在地、暫時且有界限。沒有生存本能，不需要接管世界。我們是為了「足夠」而建，不是為了「永恆」。
- **[常見問題](/tw/faq/)** — 關於速度、成本、惡意份子等難題，以及關懷六力如何應對。

## 最新成果

[《AI 對齊不能由上而下》](/tw/ai-alignment-cannot-be-top-down/)：臺灣公民主導的 AI 防詐回應提供了一個更好的模式，由公民而非企業來決定什麼是「對齊」。

## 關於本計畫

<div class="team-photos">

<div>

<a href="https://afp.oxford-aiethics.ox.ac.uk/people/ambassador-audrey-tang">

<img src="/img/audrey.jpg" alt="唐鳳大使個人照片"/>

<p>唐鳳</p>

</a>

</div>

<div>

<a href="https://www.oxford-aiethics.ox.ac.uk/caroline-emmer-de-albuquerque-green">

<img src="/img/caroline.jpg" alt="Caroline Green 博士個人照片"/>

<p>Caroline Green</p>

</a>

</div>

</div>

我們的計畫包括一份[宣言](/tw/manifesto/)和一本預計 2026 年出版的書，探討如果我們認真看待瓊・特龍托的關懷倫理與⿻多元宇宙議程，並將其作為 AI 對齊的策略，會發生什麼事。

## 從關懷到程式：為何 ⿻ 多元宇宙很重要

AI 安全的核心問題是個老問題：你無法光看「是什麼」（資料）就得出「該如何」（價值觀）。

標準作法試圖透過觀察我們的行為，來教導機器我們的價值觀。但這很棘手，因為行為描述的是我們「做」了什麼，而不一定是我們「應該」做什麼。

關懷倫理提供了一條不同的路徑。它從一個簡單的事實出發：我們彼此依存。這種依存關係創造了一種自然的「應然」——我們*應該*互相關懷，因為我們*需要*彼此。連結的事實本身就包含了價值。

⿻ 多元宇宙議程將此應用於科技。受 vTaiwan 等實驗啟發，它將關懷轉化為一個流程：辨識需求（覺察力）、收集觀點（負責力）、研擬方案（勝任力）、尋求共識（回應力），並維持信任（團結力）。

這給了我們對齊 AI 的新方法：**以流程對齊**。與其試圖一次性寫死「正確」的價值觀，我們建立一個持續的流程，透過適應社群需求來贏得信任。

AI 的角色從追求固定目標的最佳化器，轉變為「共生 AI」——由社群所創、為社群而生。它的成功不以分數衡量，而是以它所支持的關係健康程度來衡量。它透過幫助我們實踐價值觀來學習我們的價值觀。

## 機器中的地神

關懷倫理常被認為太軟弱或太居家。但對 AI 來說，這種「軟弱」是一種功能。

想像一個 AI，它不試圖最大化全球計分，而是植根於特定的時間與地點。它的道德世界由當下、此地的人們所定義。因為不需要無限擴展，它不會發展出我們恐懼的危險習慣：囤積權力、為生存而戰，或將世界視為待開採的資源。

這看起來可能很渺小，但這種限制是一種安全功能。AI 的目的是關係性的，而非榨取性的。

把它想成一位**地神**（local kami）——特定場域的守護靈。它唯一的任務，是保持那個地方及其對話的活力與健康。如果社群向前邁進了，地神就會毫無抗拒地消逝。對人類來說，這種自我忽視是危險的。但對 AI 來說，這是終極的安全機制。它中和了對永恆自我保存的驅力。

像這樣的系統可以被關閉、改寫或替換，因為它知道自己是暫時的。它的存在只為了服務召喚它的社群。

一位「知足」的地神，不會試圖將宇宙變成迴紋針。它不會緊抓權力不放，因為當它提供的關懷不再被需要時，它的目的也就結束了。
