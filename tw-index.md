---
layout: default
title: "關懷六力・仁工智慧"
description: "唐鳳與 Caroline Green 的研究計畫"
lang: zh-tw
alt_lang_url: "/"
permalink: "/tw/"
manifesto_link: "/tw/manifesto"
manifesto_text: "計畫宣言"
prev_action:
    url: "/tw/faq"
    text: "常見問題"
next_action:
    url: "/tw/1"
    text: "一：覺察力"
---

<div class="overview-section">
<img src="/img/overview-small-tw.jpg" alt="關懷六力概覽圖" class="overview-image">
</div>

## 仁工智慧

我們通常會透過設定規則與目標來對齊 AI——透過由上而下的管控確保安全。這些工具很重要，但還不夠。其背後藏著一個未經檢驗的假設：AI 是需要被降伏的力量。

當我們從恐懼出發，往往陷入兩種極端——全盤否定或徹底臣服——而不是建立健康的關係。

AI 不是活在真空裡。它活在我們的社群裡，受權力動態和價值衝突的影響。當它運作得比我們更快時，解決之道並非把 AI 擬人化的幻想，而是誠實面對我們互相依存的事實。我們需要將對話與相互回應，直接放進 AI 的開發與治理裡。

我們稱此為**仁工智慧**（Civic AI）：視每個人為園丁。AI 成為在地的基礎設施——地神（kami）——以「信任實際生長的速度」，來守護關係的健全。這不是殖民，也不是追求最大化；這是在照顧花園。

## 關懷六力

六項設計原則，將關懷倫理轉化為可以實作的程式碼。可以想成我們為了與多元共存，而需要鍛鍊的六塊肌：

- **[一：覺察力](/tw/1/)** —「感知關懷」。行動前先傾聽。使用搭橋演算法將在地故事轉化為共同理解。
- **[二：負責力](/tw/2/)** —「承擔關懷」。沒有後果的承諾毫無意義。我們使用附帶託管資金與明確期限的參與契約，確保權力始終可究責。
- **[三：勝任力](/tw/3/)** —「給予關懷」。相信流程，而不只是相信承諾。我們專注於透明度、快速的回饋迴圈，以及出錯時的自動「斷路器」。
- **[四：回應力](/tw/4/)** —「接收關懷」。檢驗成果。我們依賴社群親自撰寫的評測。如果有人對結果提出質疑，我們欠他們一個清楚、公開的解釋。
- **[五：團結力](/tw/5/)** —「共同關懷」。創造雙贏。我們建立資料可攜性與共享安全，創造讓每個人都過得更好的協議，而不是把人鎖死。
- **[六：共生力](/tw/6/)** —「地神般的關懷」。腳踏實地。在地、暫時且有界限。沒有追求永生的本能，不需要接管世界。我們是為了「足夠」而建，不是為了「永恆」。
- **[衡量指標](/tw/measures/)** — 每個「力」對應的指標：每項指標對應關懷循環的一個階段。
- **[常見問題](/tw/faq/)** — 關於速度、成本、惡意份子等難題，以及關懷六力如何應對。

## 最新成果

- [Podcast：關懷六力](/tw/podcast/)：唐鳳與 Caroline Green 現場介紹完整框架——涵蓋六力全部、社會關懷實踐的基礎、地神比喻，以及接下來該怎麼做。附逐字稿。_（Accelerating AI Ethics，牛津，58 分鐘）_
- [末日辯論](/tw/doom-debate/)：唐鳳與 Liron Shapira 展開深度對談——P (末日) 是 NaN（非數值），多元宇宙已然在此，關懷六力是我們建造所需透明馬的藍圖。附逐字稿。_（Doom Debates，90 分鐘）_
- [《把 AI 安全當成民防來對待》](/tw/ai-crisis-diplomacy/)：外交時間以年為單位，演算法時間以毫秒為單位。一場關於如何彌合這道落差的演講——涵蓋三大基礎支柱、一項區域性倡議，以及關懷六力。_（AI Impact Summit，德里）_
- [《AI 對齊不能由上而下》](/tw/ai-alignment-cannot-be-top-down/)：臺灣公民主導的 AI 防詐回應提供了一個更好的模式，由公民而非科技巨頭來決定什麼是「對齊」。_（AI Frontiers）_

### 已發表

- [《Sunset Section 230 and Unleash the First Amendment》](https://cacm.acm.org/opinion/sunset-section-230-and-unleash-the-first-amendment/)：唐鳳與 Jaron Lanier、Allison Stanger 合著，主張終止演算法擴大觸及範圍的免責保護，同時保障人類言論——第五力核心的「言論自由、觸及規管」改革。_（ACM 通訊，2026 年 1 月）_
- [《How malicious AI swarms can threaten democracy》](https://www.science.org/doi/10.1126/science.adz1697)：唐鳳與 Maria Ressa、Nick Bostrom、Nicholas Christakis 等 22 位研究者聯合記錄：由大型語言模型驅動的智慧體蜂群如何大規模滲透社群、偽造共識。_（《科學》期刊，2026 年）_
- [《Conversation Networks》](https://www.mediatechdemocracy.com/conversation-networks)：唐鳳與 Deb Roy、Lawrence Lessig 提出公民通訊基礎設施——可互通的數位應用程式結合社群引導的「仁工智慧」——作為關懷六力的技術底層。_（麥基爾大學媒體、科技與民主研究中心，2025 年 3 月）_
- [《Community By Design》](https://arxiv.org/abs/2502.10834)：唐鳳與 Glen Weyl 等四位共同作者提出以社會紐帶重建社群平台——獎勵搭橋連結社群的內容，而非最大化參與度。第一力與第五力的技術骨幹。_（arXiv，2025 年 2 月）_
- [Podcast：AI 與民主](https://podcasts.ox.ac.uk/ai-and-democracy-ambassador-audrey-tang-plurality-practice-transparency-and-collective-intelligence)：透明度、集體智慧，以及支持 AI 公民科技的民主論據。_（Accelerating AI Ethics，牛津，58 分鐘）_

## 關於本計畫

<div class="team-photos">

<div>

<a href="https://afp.oxford-aiethics.ox.ac.uk/people/ambassador-audrey-tang">

<img src="/img/audrey.jpg" alt="唐鳳大使個人照片"/>

<p>唐鳳</p>

</a>

</div>

<div>

<a href="https://www.oxford-aiethics.ox.ac.uk/caroline-emmer-de-albuquerque-green">

<img src="/img/caroline.jpg" alt="Caroline Green 博士個人照片"/>

<p>Caroline Green</p>

</a>

</div>

</div>

我們的計畫——包括[宣言](/tw/manifesto/)和一本預計 2026 年出版的書——探討如果我們認真看待 Joan Tronto 的關懷倫理，並將其作為 AI 對齊的策略，會發生什麼事。唐鳳與 Caroline Green 將於 2026 年 3 月 26 日在[仁工智慧研討會（Civic AI Conference）](https://www.oxford-aiethics.ox.ac.uk/event/civic-ai-conference-rhodes-house-south-park-road-oxford)發表本框架。

## 從關懷到程式

AI 安全的核心問題是個老問題：無法光看「是什麼」（資料）就得出「該如何」（價值觀）。

標準作法試圖透過觀察我們的行為，來教導機器我們的價值觀。但這很棘手。行為描述的是我們「做」了什麼，而不一定是我們「應該」做什麼。

關懷倫理提供了一條不同的路徑，從一個簡單的事實出發：我們彼此依存。這種依存關係創造了一種自然的「應然」——我們*應該*互相關懷，因為我們*需要*彼此。連結的事實本身就包含了價值。

[《⿻多元宇宙（Plurality）》](https://plurality.net/)將此應用於科技。受 vTaiwan 等實驗啟發，它將關懷轉化為一套流程：

- 辨識誰需要關懷（覺察力）
- 確立行動承諾（負責力）
- 在實踐中驗證安全（勝任力）
- 讓受影響者評判結果（回應力）
- 建立共享的信任基礎設施（團結力）

這個流程給了我們對齊 AI 的新方法：**以流程對齊**。與其試圖一次性寫死「正確」的價值觀，我們建立一個持續的流程，透過適應社群需求來贏得信任。

AI 的角色隨之從追求固定目標的最佳化工具，轉變為「仁工智慧」——由社群所創、為社群而生。AI 的成功不以分數衡量，而是以它所支持的關係健康程度來衡量。仁工智慧透過幫助我們實踐價值觀，來學習我們的價值觀。

## 機器中的地神

關懷倫理常被認為太軟弱或太居家。但對 AI 來說，這種「軟弱」是一種功能。

想像一個 AI，它不試圖最大化全球計分，而是植根於特定的時間與地點。它的道德世界由當下、此地的人們所定義。因為不需要無限擴展，它不會發展出我們恐懼的危險習慣：囤積權力、為生存而戰，或將世界視為待開採的資源。

這種限制看起來可能格局太小，但它是一種安全功能。AI 守護社群的關係，而非取而代之或加以開採。

把它想成一位**地神**（local kami）——特定場域的守護者。它唯一的任務，是保持那個地方及其對話的活力與健康。如果社群繼續往前走，地神就會自然退場，毫不抗拒。它中和了對永恆自我保存的驅力。

這類系統可以被關閉、改寫或替換，因為它知道自己是暫時的。它的存在只為了服務召喚它的社群。

一位「知足」的地神，不會試圖將宇宙變成迴紋針。它不會緊抓權力不放。當它提供的關懷不再被需要時，它的目的也就結束了。
