---
layout: default
title: "6-Pack of Care"
header_title: "6-Pack of Care"
subtitle: "Institute for Ethics in AI"
description: "Research project by Audrey Tang and Caroline Green"
lang: en-gb
alt_lang_url: "/tw/"
manifesto_link: "/manifesto"
manifesto_text: "Manifesto"
next_action:
    url: "/1"
    text: "Pack 1: Attentiveness in Recognition"
    arrow: "right"
---

<div class="overview-section">
<img src="/img/overview-small.jpg" alt="6-Pack of Care visual overview" class="overview-image">
</div>

## The Case for Relational Alignment

We usually try to align AI by giving it rules and goals—top-down controls to keep it safe. While these methods are vital for technical safety, they aren't enough.

AI doesn't coexist in a vacuum. It lives in our communities, shaped by power dynamics and clashing values. As AI systems move faster than we can discuss them, we need more than just safeguards. We need to bake interdependence, dialogue, and mutual responsiveness right into how we build and govern those systems.

We call this **civic care**. Rooted in care ethics and the Plurality movement, this approach treats us all as gardeners. AI becomes local infrastructure—a spirit of place, a **_kami_**—that supports care _at the speed trust actually grows_. It's not about colonising or maximising; it's about tending to the garden.

## The 6-Pack

Six design principles turn care ethics into something we can code. Think of them as muscles we need to train to live well with diversity:

- **[Pack 1: Attentiveness](/1/)** — "Caring about." Listen before leaping. Use bridging algorithms to turn local stories into shared understanding.
- **[Pack 2: Responsibility](/2/)** — "Taking care of." Commitments mean nothing without consequences. We use engagement contracts with escrowed funds and real deadlines to ensure power is always accountable.
- **[Pack 3: Competence](/3/)** — "Care-giving." Trust the process, not just the promise. We focus on transparency, fast feedback loops, and automatic "circuit breakers" if things go wrong.
- **[Pack 4: Responsiveness](/4/)** — "Care-receiving." Check the results. We rely on evaluations written by the community itself. If someone challenges the outcome, we owe them a clear, public explanation.
- **[Pack 5: Solidarity](/5/)** — "Caring with." Make it win-win. We build for data portability and shared safety, creating deals where everyone is better off, rather than locking people in.
- **[Pack 6: Symbiosis](/6/)** — "Kami of care." Keep it grounded. Local, temporary, and bounded. No survival instinct, no need to take over the world. We build for "enough," not "forever."
- **[Frequently Asked Questions](/faq/)** — The hard questions: What about speed? Cost? Bad actors? And how the 6-Pack handles them.

## Latest

["AI Alignment Cannot Be Top-Down"](/ai-alignment-cannot-be-top-down/): Taiwan's citizen-led response to AI-enabled scams offers a better model where citizens, not corporations, decide what “aligned” means.

## About the Project

<div class="team-photos">

<div><a href="https://afp.oxford-aiethics.ox.ac.uk/people/ambassador-audrey-tang">
<img src="/img/audrey.jpg" alt="Photo of Ambassador Audrey Tang">
<p>Audrey Tang</p>
</a></div>

<div><a href="https://www.oxford-aiethics.ox.ac.uk/caroline-emmer-de-albuquerque-green">
<img src="/img/caroline.jpg" alt="Photo of Dr. Caroline Green">
<p>Caroline Green</p>
</a></div>

</div>

Our project—a [manifesto](/manifesto/) and a book arriving in 2026—explores what happens when we take Joan Tronto's care ethics seriously as a strategy for AI alignment.

## From Care to Code

The core problem of AI safety is an old one: You can't get "what should be" (values) just by looking at "what is" (data).

Standard approaches try to teach machines our values by watching how we behave. But that's tricky. Behaviour describes what we do, not necessarily what we _should_ do.

Care ethics offers a different path, starting with the simple fact that we depend on each other. That dependency creates a natural "ought"—we _should_ care for one another because we _need_ one another. The fact of our connection contains its own value.

[⿻ Plurality](https://plurality.net/) applies this to technology. Inspired by experiments like vTaiwan, it turns care into a process:

- Recognising who needs care (Attentiveness)
- Binding commitments to act (Responsibility)
- Demonstrating safety in practice (Competence)
- Letting the affected judge results (Responsiveness)
- Building shared infrastructure for trust (Solidarity)

This process gives us a new way to align AI: **alignment-by-process**. Instead of just trying to code the "right" values once and for all, we build a continuous process that earns trust by adapting to what the community needs.

The AI then shifts from being an optimiser chasing a fixed goal to a "Symbiotic AI"—something created by and for the community. AI's success isn't measured by a score, but by the health of the relationships it supports. Symbiotic AI learns our values by helping us practice them.

## Kami in the Machine

Care ethics is often dismissed as too soft or domestic. But for AI, that "softness" is a feature.

Imagine an AI that isn't trying to maximise a global score, but is instead rooted in a specific place and time. Its moral world is defined by the people right here, right now. Because it doesn't need to scale indefinitely, it doesn't develop the dangerous habits we fear: hoarding power, fighting for survival, or treating the world like a resource to be mined.

That limit might seem small, but it's a safety feature. The AI's role is relational, not extractive.

Think of it like a local **_kami_**—a spirit of a specific place. Its only purpose is to keep that place and its conversation alive and healthy. If the community moves on, the _kami_ fades away without a fight. For a human, that kind of self-neglect is dangerous. For an AI, it's the ultimate safety mechanism. It neutralises the drive for eternal self-preservation.

This type of system can be turned off, rewritten, or replaced because it knows it is provisional. It exists only to serve the community that summoned it.

A _kami_ that knows "enough is enough" won't try to turn the universe into paperclips. It won't cling to power. Its purpose ends when the care it provides is no longer needed.
