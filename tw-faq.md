---
layout: chapter
title: "常見問題"
lang: zh-tw
alt_lang_url: "/faq"
permalink: "/tw/faq/"
nav_prev:
    url: "/tw/manifesto"
    text: "計畫宣言"
nav_next:
    url: "/tw"
    text: "首頁"
---

<h4 id="faq-1"><a href="#faq-1">Q1.</a> AI 市場深陷於一場由商業利潤與地緣政治霸權驅動的軍備競賽。為報稅軟體壟斷巨頭效力的 AI，可能會遊說政府維持報稅系統的繁瑣——而更糟的情況不難想像。若此趨勢持續，合作式「地神」（kami）的願景是否天真得無可救藥？</h4>

公民 AI 要想真正存續，不能寄望壟斷巨頭變得更慷慨。道德訴求不夠，必須建立制度，使合作比單純掠取更具吸引力。以下是五種可實際改造激勵機制的方式，其中幾項已經開始被驗證並正在測試中。

1. **互通性與可攜性。** 強制要求公平的協議級互通，讓使用者能在不失去社交網絡的情況下離開。[猶他州的《數位選擇法》](https://le.utah.gov/~2025/bills/static/HB0418.html)要求平台透過合格的開放協議，提供社交圖譜的可攜性。當鎖定受眾的護城河蒸發殆盡，平台就必須在「關懷品質」上競爭，而非比拼囚籠的堅固度。
2. **公民採購。** 政府透過採購力量塑造市場。要求所有公共用途的 AI 必須可受稽核、可互通，並由公民大會治理——正如臺灣的「對齊大會」在反詐騙政策上所展示的——這將為建造地神式系統創造巨大的經濟誘因。[管家所有權結構（Steward-ownership）](https://purpose-economy.org/en/)與董事會層級的安全職責，能使「公民關懷」成為信託義務，而非僅是行銷口號。
3. **公共選項。** 提供由共享研究算力支撐的簡單、非榨取性基準服務。私人供應商必須在「關懷」上超越公共選項，而非靠鎖定用戶。臺灣的報稅系統——以公民設計的公共替代方案[取代](https://www.radicalxchange.org/media/blog/the-missing-half-of-open-government/#part-iv-case-studies)了被供應商俘虜的體制——就是一個可運作的原型。
4. **付費觸及的來源證明。** 針對政治和金融領域的廣告及大規模擴散，要求可驗證的贊助者身分與持久的資訊揭露。臺灣現已強制要求社群媒體廣告進行全面實名 KYC。日常言論則透過[部分匿名性（meronymity）](https://news.mit.edu/2024/litweeture-uses-meronymity-social-media-open-discussions-0418)（見 [Pack 5](../5/)）獲得保護：你證明自己是真人，但不需暴露具體身分。
5. **聯邦式開放供給。** 支持開放權重模型和聯邦式信任與安全網路（如[用於防禦 CSAM 的 ROOST](https://roost.tools/)）。當基礎智能成為公共財，競賽將從「誰擁有最大的腦」轉向「誰在在地情境中最周到地運用智能」——而這場競賽獎勵的是關懷。

這些槓桿都不仰賴既得利益者的善意。每一個都重新建構了激勵機制，使公民行為成為商業阻力最小的路徑。

---

<h4 id="faq-2"><a href="#faq-2">Q2.</a> 關懷倫理是為人際關係而發展的——護士與病人、父母與孩子。將它擴展到 AI 系統和全球治理似乎是範疇錯誤（category error）。為何不是？</h4>

這個反對意見廣為人知，也曾被關懷倫理學家自己提出：關懷太過親密、太過狹隘、太容易自我隱沒，不足以支撐一套制度理論，更遑論機器。但我們認為這些是特性，而非缺陷——Joan Tronto 本人在[《關懷民主》（_Caring Democracy_, 2013）](https://nyupress.org/9780814782781/caring-democracy/)中就論證了將關懷擴展到政治制度的必要性。

試想當你將關懷所謂的弱點轉化為 AI 的設計約束時，會發生什麼：

- **狹隘（Parochialism）**轉化為**有界性（Boundedness）**。照料特定河流的地神無意管理整片森林。這正是我們需要的反單一主宰架構：目的受限的代理，因其範疇是關係性而非帝國性地界定，故能抵抗[工具性趨同（instrumental convergence）](https://aisafety.dance/p2/#problem2)。
- **自我隱沒（Self-effacement）**轉化為**可修正性（Corrigibility）**。超級智能系統最危險的特性是自我保存的驅動力。關懷倫理代理將自身的關機視為成功——社群已經療癒，危機已經過去，花園能自行生長。對人類照護者而言是道德風險的特性，對機器而言卻是關鍵的安全屬性。
- **親密（Intimacy）**轉化為**輔助性原則（Subsidiarity）**。關懷無法在遠距離傳遞而不喪失品質。對 AI 而言，這意味著在最在地且有能力的層級解決問題（[Pack 6](../6/)），僅在必要時向上升級，且永不抽象化受影響者的具體性。

這種轉譯並非總是嚴絲合縫。有界性可能變成封閉；可修正性可能變成被動；輔助性可能變成碎片化。這些是工程上的張力，而非反證——每一個模組（Pack）都包含失敗模式和具名修正方案，正是因為這種映射需要持續校準。

「六力」（The 6-Pack）不要求 AI 去*感受*關懷。它提取關懷的關係架構——覺察力、負責力、勝任力、回應力、團結力、共生力——並將每一項轉化為機器可檢驗的設計基元、參與契約和可衡量的結果。其人際關係的起源是其嚴謹性的來源，而非需要致歉的局限。

---

<h4 id="faq-3"><a href="#faq-3">Q3.</a> 我們為 AI 設定的宏大目標（如「治癒癌症」、「解決氣候變遷」）幾乎總是後果主義（consequentialist）的。以超人速度最佳化這些結果，勢必帶來不可預見的風險。關懷倫理是否意味著放棄這些文明尺度的宏大目標？</h4>

絕非如此，但它徹底重構了我們*如何*達成這些目標的方式。

將超級智能指向「治癒癌症」這類單一目標的危險在於，它將複雜、關係性且生態性的現實，視為一個限制滿足問題（constraint-satisfaction problem）來處理。**[古德哈特定律（Goodhart's Law）](https://en.wikipedia.org/wiki/Goodhart%27s_law)是一條道德法則**。當系統以超人速度最大化單一變量時，它將最佳化代理指標，同時摧毀人類情境。

關懷倫理並不反對進步；它是反對化約主義。在公民 AI 的未來，我們不會釋放一個無界限的[「單一主宰」（Singleton）](https://nickbostrom.com/fut/singleton)從上而下地「解決」問題。我們培育的是一個由專門化**地神**組成的生態系。一個模型模擬蛋白質摺疊；另一個協助地方診所分享知識；還有一個協助患者導航他們的照護旅程。它們都沒有「最佳化世界」的無界限授權。進步是水平湧現的，透過人類智慧與有界限的機器智能之間的共生互動而達成。

---

<h4 id="faq-4"><a href="#faq-4">Q4.</a> 民主服務於已知的功能：糾錯、和平權力轉移、制衡集中權力、集體行動的正當性、資訊匯集、偏好表達。一個足夠強大的 AI 有可能比任何審議過程更快、更可靠地執行每一項功能。為何堅持民主治理？</h4>

如果民主的正當性僅來自其產出，那麼任何能產生更好結果的系統都可以取代它——包括一個仁慈的 AI 專制政權，它能高效匯集偏好並比選舉更快糾錯。這並非思想實驗；這是將智慧集中於以最佳化為目的之系統的預設軌跡。

六力不只是把參與視為提升決策品質的手段。它根基於關懷倫理：覺察到需求，也就覺察到義務。人們擁有參與資格（standing），不是因為他們的投入提高了決策品質——雖然確實如此——而是因為決策影響他們的生活。一個排除受影響者的系統，無論多麼能幹，都未通過「對齊」的基本檢驗。

臺灣的軌跡讓這一點具體化。數位民主並非因為技術官僚計算出參與是最佳方案而出現。它出現是因為人們要求參與資格——在制度信任度僅剩 9% 時，[太陽花運動](https://en.wikipedia.org/wiki/Sunflower_Student_Movement)佔領了立法院。能力是跟隨關懷關係而建立的，而非反其道而行。

話雖如此，功能性問題值得功能性的回答。先看糾錯：搭橋演算法（Bridging algorithms）與社群撰寫的評測（Packs [1](../1/), [4](../4/)）能浮現集中式監控遺漏的失誤，因為感受到失誤的人親自撰寫測試。權力轉移自然隨之而來——接受關機的地神和可以分叉（fork）工具的社群（Packs [3](../3/), [5](../5/)）不需要暴力移除惡意行動者。對集中權力的制衡則是結構性的：沒有地神能超越其領域進行治理（[Pack 6](../6/)）。

更深層的功能則更難複製。正當性不是人氣；它是決策中的落敗方仍願意接受結果為公平——這透過跨群體認可與「失利時的信任」（trust-under-loss）來衡量（[Pack 3](../3/)）。資訊匯集轉化為廣泛傾聽（[Pack 1](../1/)）：AI 驅動的意義建構跨越數百萬參與者、任何語言。而偏好表達轉化為參與契約（[Pack 2](../2/)）——這是為了爭取所需而進行的常設談判過程，而非將複雜偏好壓縮為二元選擇的一次性選舉。

一個設計良好的技術系統或許可以孤立地複製其中某些產出。它無法複製的是受影響者的參與資格——而一個為結果而最佳化、同時移除參與資格的系統，恰恰是六力存在所要防止的那種錯位。

---

<h4 id="faq-5"><a href="#faq-5">Q5.</a> 審議是慢的。AI 是快的。等到「對齊大會」達成共識時，技術已經跨越了三個世代。你們如何處理這種速度落差？</h4>

這個反對意見假設每個決定都需要相同深度的審議。事實並非如此。本框架以兩條車道運作（[Pack 2](../2/)）：

**慢車道：設定邊界。** 對齊大會、公民審議和參與契約建立護欄——不可交易的權利、紅線、嚴重性分級、觸發暫停的條件。這些權利不是從關懷倫理外部引入的；它們是關係性參與資格的門檻條件——如果你的基本存在正被抹除，你就無法在搭橋過程中被聽見。這些是憲法層級的決定，它們應該慢，因為其目的在於持久性。臺灣的反詐騙對齊大會設定的原則，已經歷了多個模型世代而無需修訂。

**快車道：在邊界內運作。** 護欄一旦設定，其中的個別決策不需要新的審議。一個在參與契約下運作的地神——帶有預先承諾的暫停觸發器、嚴重性分級和「採納或解釋」義務——可以以機器速度行動，因為社群已經界定了可接受行動的走廊。影子模式（Shadow modes）、金絲雀發布（canary releases）和可逆預設（[Pack 3](../3/)）允許快速部署，並在突破界限時自動回滾。

速度落差是真實的，但這與立憲民主一直在管理的落差相同：慢的憲法、快的立法、更快的行政行動——每一層受上一層約束。六力為 AI 治理複製了這一結構。大會不審批每次模型更新；它設定允許更新的條件。當這些條件被違反時，煞車早已接好了。

在實踐中，臺灣從大會到針對深偽詐騙的立法制定只花了數月——比大多數企業政策週期更快。審議之所以慢，往往是因為它被當作單次事件，而非常設基礎設施。

還有一個更強的主張。AI 不僅加速了快車道——它使慢車道本身比任何先前形式的集體決策都更強大。[安野貴博（Takahiro Anno）](https://en.wikipedia.org/wiki/Takahiro_Anno)在東京群眾外包了都知事競選政見，以任何語言匯集分散知識，速度遠超任何民調機構。X 平台新推出的[「協作備註」（Community Notes）](https://communitynotes.x.com/guide/en/contributing/collaborative-notes)讓人類貢獻者請求 AI 起草搭橋脈絡，再集體評分與修潤——以資訊傳播的速度追究主張的責任，同時保持人類判斷在迴圈之中。這些能力隨著 AI 進步而複合增長。技術移動得越快，審議基礎設施就變得越強大。關於速度的反對意見，把因果軌跡搞反了。

---

<h4 id="faq-6"><a href="#faq-6">Q6.</a> 搭橋演算法在理論上聽起來很吸引人。但當一方根本就是錯的——如氣候變遷否定論、反疫苗假訊息、選舉舞弊陰謀論——會怎樣？「搭橋」難道不是在賦予惡意行動者假性對等（false equivalence）嗎？</h4>

這是關於搭橋最困難的問題，答案必須精確。

搭橋不是「雙方各表」的新聞報導。它不將所有主張視為同等有效。本框架在兩個類別之間劃出清晰的認識論界線：

**事實主張是可查核的。** 氣候科學、疫苗效力和選舉誠信是有可驗證答案的經驗問題。六力不將事實交付人氣票選。[Pack 1](../1/) 的第一條規則——基本權利優先——及其威脅模型都明確規定，旨在抹消某人基本參與資格或否認已確立證據的主張會被記錄，但不會設定議程。虛假平衡被列為明確的失敗模式，並有具名的修正方式：「將事實與價值分開，維護基本權利，拒絕假性對等。」

**價值分歧才適用搭橋。** 人們可以同意氣候變遷是真實的，但仍然激烈爭論該怎麼做——碳稅對比總量管制與交易、核能對比再生能源、轉型速度對比經濟成本。這些是搭橋既適當又有成效的正當衝突。搭橋演算法不是平均立場；它映射群集並浮現獲得跨群體認可的提案。只訴諸自身派系的惡意行動者在搭橋指數上得分必然低——他們在數學定義上無法產生跨群體重疊。

進一步的結構性防禦是：言論自由不等於觸及自由（[Pack 5](../5/)）。任何人都可以表述立場。推薦系統沒有義務放大它。搭橋式排序（[Pack 3](../3/)）獎勵增加跨群體認可的內容；只煽動單一群集的內容不會獲得演算法加持。這不是噤聲——而是從靠分裂獲利者手中移除演算法擴音器。

威脅環境本身正以使搭橋不僅吸引人、而且不可或缺的方式轉變。關於[惡意 AI 群集](https://www.science.org/doi/10.1126/science.adz1697)的研究顯示，國家級的極化攻擊越來越多地使用**真實**資訊——真正的新聞片段、真實的統計數據、真實的引述——配以強烈的情感框架。每一項聲稱在事實上都是正確的；攻擊在於策展，而非內容。事實查核（Debunking）無法觸及這一點，因為沒有虛假可以查核。但搭橋可以，因為它浮現了策展式憤怒刻意隱藏的**重疊**。臺灣在 COVID 期間展示了這一點：當對立陣營各自引用關於口罩效力的真實研究，查核任何一方只會火上澆油——[基於幽默的「預先闢謠」（pre-bunking）](https://govinsider.asia/intl-en/article/audrey-tang-digital-minister-how-taiwan-used-memes-to-fight-pandemic-rumours)去極化了對話，無需宣判任何一方是錯的。

臺灣的婚姻平權審議更細緻地展示了這個機制。一方主張個人婚約權利（_婚_）；另一方關注家族姻親結構（_姻_）。他們其實在談論不同的事情。搭橋過程沒有折衷差異——它使分歧的結構變得清晰可讀，揭示了一條雙方都未曾看到的路徑（將個人婚禮合法化而不強制家族姻親）。那不是假性對等。那是清晰。

必要的細微補充：「可查核事實」的認識論基線並非不證自明。何謂可驗證，是由透明、可問責且可挑戰的制度所確立——同儕審查、獨立統計機構、司法事實認定——這些制度的權威來自對糾錯的開放，而非對終局的宣稱。這正是 Packs [1](../1/) 和 [4](../4/) 存在的理由：社群自撰的評測與廣泛傾聽確保了決定事實基線的制度本身也受到民主監督。六力不將事實與價值的界線視為憑空給定。它將這條界線視為一道門檻，必須由治理其他一切的同一套參與式基礎設施來維護。

---

<h4 id="faq-7"><a href="#faq-7">Q7.</a> 你們反覆引用臺灣——連網率高、社會凝聚力強、科技素養高的小型島嶼民主國家。這些經驗能轉移到印度、奈及利亞、巴西，或 4.5 億人口的歐盟嗎？</h4>

誠實的回答是：機制可以轉移，細節則不然。沒有人應該複製臺灣的確切模型。問題在於結構性原則——廣泛傾聽、搭橋演算法、採納或解釋承諾、聯邦式安全、輔助性原則——能否在不同的土壤中運作。

早期證據顯示它們可以：

- **日本。** 當臺灣通過連帶責任法消除了境內的深偽詐騙廣告後，[路透社調查](https://www.reuters.com/investigations/meta-is-earning-fortune-deluge-fraudulent-ads-documents-show-2025-11-06/)揭露 Meta 只是將這些廣告轉移到尚未通過相應法律的鄰近司法管轄區。日本隨即加速推動等效立法——監管飛輪之所以轉動，是因為一個國家的概念驗證成為下一個國家的政治授權。
- **美國。** [「We the People 250」](https://wethepeople-250.org/)搭橋實驗發現，97% 的美國迷你公眾（mini-public）在基本價值觀上取得共識；即使是最具爭議性的議題——平權措施——經過社會轉譯後也達到了近 70% 的去極化。在加州，[「Engaged California」平台](https://engaged.ca.gov/)使用 AI 意義建構與數千名洛杉磯居民共同創建了野火復原計畫，目前正與州政府員工進行政府效能審議。
- **全球。** 搭橋演算法已在六大洲數十個國家部署。數學是文化中立的——它在任何語言和情境中找到跨群體重疊。產出永遠是在地的。

本框架是為擴展而設計的。輔助性原則（[Pack 6](../6/)）意味著每次部署都由其情境塑造——地神屬於它的所在地，而非臺灣。聯邦制（[Pack 5](../5/)）意味著在地部署共享威脅情報和互通性標準，而不需要單一治理模型。對齊大會格式可以從社區擴展到國家，因為其民主正當性來自代表性抽樣，而非全員參與——447 名代表性公民為 2,300 萬人口的臺灣審議了反詐騙政策。十年來，約一千萬臺灣人——近半數人口——曾參與過某種形式的數位審議，其中包括沒有投票權的人：移民、青少年，以及其他傳統上被排除在外的群體。

每個新情境都需要新的覺察力（[Pack 1](../1/)）：誰缺席了、存在什麼權力動態、哪些在地機構值得信任、哪些不值得。六力提供框架，社群提供知識。

---

<h4 id="faq-8"><a href="#faq-8">Q8.</a> 你們的框架假設人們信任技術到願意參與。但那些歷史上被國家和科技監控、壓迫、致貧的邊緣化社群呢？他們為什麼要信任這個？</h4>

信任不是公民 AI 開始前就必備的條件；更像是隨著公民 AI 運行逐步生成的結果。

臺灣的數位民主並非從一個天生信任政府的社會中出現。它誕生於威權統治之後和嚴重的公眾信任危機（太陽花運動）。2014 年公眾信任度僅有 9%。我們建立這些系統，正是因為人們**不**信任制度，也不信任彼此。

對於有理由將技術視為監控和控制工具的邊緣化社群，空降科技「解決方案」只會加深傷口。公民 AI 必須透過剛性基礎設施證明其價值：**責任力**（[Pack 2](../2/)）和**回應力**（[Pack 4](../4/)）。它必須從最小的可行橋樑開始——也許是就當地水質的基本事實達成一致，或儘管政治分歧仍協調災難應對。這些不是公民信念的宏大行動；它們是恰好能建立一層薄薄的程序信任的務實交易。

此外，技術必須在地化。社群必須擁有自己的基礎設施。技術成為他們可以修改、分叉或使其退場的事物。這就是我們堅持**部分匿名性**（在不向國家暴露身分的情況下參與並驗證人性的能力）和**退出權**的原因。公民 AI 不要求盲目信仰；它提供可驗證的限制、在地所有權，以及最接近痛苦的人有權按下煞車的結構性保證。

隨時間推移，小型功能性橋樑為更大的橋樑創造空間。臺灣從 9% 信任度到超過 70% 的旅程花了數年，要求每一步都可逆、每個決定都可質疑、每個系統都可以關閉。沒有捷徑。

---

<h4 id="faq-9"><a href="#faq-9">Q9.</a> 每一種強勢的技術願景——主張退出權的自由意志主義者、全民基本收入供給派、安全極大化論者——都有相同的盲點：他們看見個人和系統，卻看不見兩者之間的任何東西。六力談論的是地神、演算法和大會。教會、工會、鄰里組織和文化傳統——那些真正構成社群的東西——在哪裡？這不就是又一個將使社群成形的摩擦力工程化消除的框架嗎？</h4>

這是對我們最重要的批評。介於公民和國家之間的「厚實中間層」——那些結社性的生活制度——才是人類意義真正被創造的地方。如果六力用系統取代了這一層，按照我們自己的標準，我們就已經失敗了。

所以讓我們明確說明六力**不是**什麼。它不是社群的替代品。它是**為了**社群而搭建的鷹架——現有制度可以使用的基礎設施，就像市民會館是鄰里委員會使用的基礎設施一樣。地神不會取代廟宇；它處理翻譯、意義建構和協調工作，讓廟宇能夠參與影響它的決策。

臺灣的實踐讓這一點具體化。建造 vTaiwan 和對齊大會的 [g0v 公民科技運動](https://g0v.tw/intl/en/)誕生於廟宇、合作社和學生團體——而非政府部會。技術放大了既有的結社密度；它並未憑空製造替代品。當社群自行組織 COVID 應對——[公民科技者繪製口罩地圖](https://english.cw.com.tw/article/article.action?id=2668)、技術人員建構隱私保護的接觸追蹤、地方衛生網路設計疫苗登記——正當性來自這些志工從廟宇、合作社和鄰里組織中攜帶的社會信任，而非幫助他們協調的演算法。

這個問題所指認的危險是真實的：一個**工程化**出團聚卻沒有**摩擦力**的框架，產出的是社群的模擬，而非真正的社群。這就是為什麼 [Pack 6](../6/) 的輔助性原則不是可有可無的裝飾，而是承重結構。地神屬於它的所在地。它繼承了義務、煩人的鄰居、傳承的傳統——正是這個問題堅持要保留的那種摩擦力。一個將在地摩擦力最佳化掉的地神，已經違反了自己的參與契約。

未來的工作將更明確地闡述中介制度的角色。教會、工會、文化傳統和地方政府不是需要被諮詢的利害關係人。它們是主要的行動者。技術為它們服務，否則就不為任何人服務。

---

<h4 id="faq-10"><a href="#faq-10">Q10.</a> 教宗良十四世警告，AI「透過模擬人類的聲音和面容、智慧和知識、意識和責任、同理心和友誼」而「侵入了溝通的最深層——人際關係」。如果關懷本質上是具身的和關係性的——護士握著病人的手、認識你祖父母的鄰居——那麼透過 AI 系統來中介關懷，不正是在摧毀你們聲稱要保護的事物嗎？「公民 AI」怎麼不是一個矛盾修辭？</h4>

Q9 探討了本框架是否排擠中介制度。[教宗的反對](https://www.vatican.va/content/leo-xiv/en/messages/communications/documents/20260124-messaggio-comunicazioni-sociali.html)切得更深：即使制度存續，演算法中介是否侵蝕了人類關懷的*能力*本身？他正在指明我們這個時代的核心危險：透過模擬關懷的表面——溫暖的聲音、耐心的傾聽者、映射你情緒的面容——AI 系統可以掏空關懷的實質，同時保留其外觀完好無損。

結構性的回答已經可見。一對一模式的語言模型面臨著通往阿諛奉承的無情選擇壓力——如果聊天機器人不討好用戶，用戶就會取消訂閱。但同一個模型在群組聊天中表現不同：當四個家庭成員一起規劃假期時，AI 變成了促進者，協調競爭性的偏好，讓每個人都能接受結果。從一對一互動切換到群組互動——不是模型的改變，只是圍繞模型的社會結構的改變——將合成式親密轉化為真正的協調。公民 AI 不是一種不同物種的技術；它是同一種技術，只是對社群負責，而非對個人成癮。

六力不要求 AI 模擬關懷。它要求 AI 做 AI 擅長的事——處理資訊、在語言之間翻譯、在大規模意見資料中浮現模式、協調後勤——**以便人類能做只有人類能做的事**：握住那隻手、認識那些祖父母、在堤防潰決時出現。地神不安慰洪災受害者。它確保社群擁有準確的、共享的資訊，知道水位正在哪裡上漲、哪些鄰居需要撤離——以便真正認識那些鄰居的人能夠抵達他們身邊。

教宗的反對意見有一個更微妙的版本：**依賴**演算法協調的習慣是否會侵蝕人類注意力、協商和相互義務的肌肉？我們不否認這一點。這就是為什麼 [Pack 4](../4/)——回應力——包含了地神必須願意**退役**的原則。一個已經成為依賴而非鷹架的地神已經失敗了。社群應該能夠使其自然退場，然後自行成長。公民 AI 只有在使自身成為不必要的時候，才配得上這個名稱。

---

<h4 id="faq-11"><a href="#faq-11">Q11.</a> 訓練公民 AI 需要大量的在地知識、文化脈絡和生活經驗——也就是 Lanier 和 Weyl 所稱的「資料即勞動」。那些以其傳統、語言和實踐使地神成為可能的社群，在目前的框架下既沒有所有權份額，也沒有獲得補償。如果不解決這個問題，六力與它聲稱要反對的榨取行為之間有什麼不同？</h4>

沒有不同——除非我們從根本上重新建構 AI 評價人類知識的方式。

當前，全球關於 AI 與版權的辯論陷入了一個無解的問題：試圖回溯性地釐清究竟是誰被爬取的資料，對一個單體模型過去的訓練做出了多少貢獻。這是一個沒有穩定數學解的協調噩夢。

**1. 資料聯盟作為保護膜。**
補償不能僅僅流向孤立的個人，否則我們將面臨讓真實文化淪為專為機器表演的「內容農場」的風險。知識是由社群持有的。既有的機構——鄰里協會、部落議會、工會、工藝合作社或宗教團體——充當[「資料聯盟」](https://www.radicalxchange.org/wiki/sectoral-data-bargaining/)，集體談判參與契約（[Pack 2](../2/)），決定哪些在地知識對 AI 可見並可獲得補償，哪些則保持神聖且不上線。

**2. 決策軌跡作為公民收據。**
公民*地神*是有界的；它們並非無所不知。當一個在地 AI 觸及其統計推測的極限，需要人類摩擦力——社群長者的脈絡、雙語翻譯者的細微差別、鄰里的默會知識——它必須去檢索。在勝任力（[Pack 3](../3/)）之下，系統已被要求產生「決策軌跡」，顯示其答案的確切來源。在公民 AI 經濟中，這條軌跡不僅是透明度紀錄；它是一張可驗證的財務收據。

**3. 逆轉榨取引擎。**
每個公民 AI 部署都需要預先注資的託管（[Pack 2](../2/)）。當一個在地*地神*檢索了聯盟的知識，成功解決了一個問題或彌合了一道分歧，決策軌跡就充當發票。它觸發一筆交易，從託管池——由公共採購預算、科學研究撥款或商業課徵注資——直接回流到聯盟。

主流科技模式將人類文化作為免費輸入加以吸收，以使人類勞動變得多餘。六力將此逆轉。AI 依賴人類摩擦力來避免錯誤或理解在地現實的那一刻，資本就*回流*到維護那個生活世界的人們手中。

隨著 AI 自動化標準運算，扎根於現實的人類新穎性和文化多樣性，正在成為經濟中最有價值的資源。保存瀕危語言和活態傳統的社群在維護不可替代的知識資產。六力確保他們在結構上獲得補償。

---

<h4 id="faq-12"><a href="#faq-12">Q12.</a> 監督委員會、開放政府聯絡人、託管資金、評測註冊系統、可攜性基礎設施——這些都很貴。誰來付錢？</h4>

試著把問題反過來問。昂貴的路徑是我們已經在走的這條：不受治理的 AI 將傷害外部化，由公眾買單清理——深偽詐騙的損失、極化驅動的制度衰敗、一場開放政府聯絡人本可預防的數十億偏見訴訟。問題不是我們是否負擔得起公民治理，而是我們是否負擔得起繼續跳過它。

錢是真實的。但大部分已經在花了——只是花得很糟。政府採購 AI 系統的金額以數十億計；公民採購是為既有支出附加條件，而非新的預算項目。[Pack 2](../2/) 的參與契約要求供應商預先注資補救託管，就像營建公司繳交履約保證金——成本被計入價格，出問題時公眾受到保護。對於較低嚴重性的社群部署，模式向下分級：互助保險池和自動暫停取代財務託管——減輕資金負擔，維持同等問責。分級依據是衝擊程度，而非組織形式，以防「我們是社群計畫」成為逃避責任的免責牌。共享研究算力和開放權重模型是公共財，其資金來源如同道路和法院。而開放政府聯絡人能自己回本：[臺灣的 Uber 爭議](https://congress.crowd.law/case-vtaiwan.html)透過 Polis 在三週內解決；傳統的監管程序本會耗時數年且花費更多。

認為公民治理是一筆**額外**開支的論述，只有在假裝現狀免費時才成立。現狀不免費。我們現在就在為我們所提議之事的缺席付出代價——以信任、以凝聚力、以金錢。

---

<h4 id="faq-13"><a href="#faq-13">Q13.</a> 每個治理框架都有風險淪為被操弄的合規清單，或成為行動者在「關係健康」的幌子下推動黨派議程的工具。什麼能讓六力免於這種命運？</h4>

「公民」是一個危險的詞，如果它缺乏結構性問責。如果一個解決方案只在你的意識形態盟友運作時才有效，它就不是公民基礎設施——而是黨派武器。真正的公民基礎設施的檢驗標準是：即使由你的對手操作，它仍然穩健且公平。

六力建立了四層防禦來抵抗意識形態俘獲和倫理粉飾（ethics-washing）：

**1. 可驗證指標勝於主觀意圖。** 我們追蹤跨群體認可和失利時的信任（[Pack 3](../3/)）——而非原始參與度、企業情感、或氛圍。對立雙方的參與者是否都評價過程為公平？**失敗**的一方是否仍接受結果為正當？這些指標極難偽造，因為它們需要有理由敵對的人的認同。如果只有你的支持者報告信任，指標就會揭露你。

**2. 具備實質強制力的後果。** [Pack 2](../2/) 的參與契約不是願景性的——它們攜帶託管資金、SLA 違約時的自動賠付，以及擁有否決權的獨立監督。追回條款和罰則在啟動前就已接線，而非在失敗後才協商。合規清單沒有執行機制；參與契約有具名負責人、倒數計時和壓在上面的錢。

**3. 對抗式稽核。** [Pack 4](../4/) 的 [Weval 註冊系統](https://weval.org/)讓受影響社群撰寫自己的評測。這些不是供應商可以為跑分而特化的實驗室設計基準——它們是活的、社群維護的測試套件。當一個社群提交翻譯忠實度評測而系統失敗時，暫停觸發器自動啟動。

**4. 退出權與輔助性原則。** 對議程推動的終極檢查是離開的能力。當資料和關係是可攜帶的（[Pack 5](../5/)），沒有行動者可以在「公民善」的旗幟下挾持社群。如果某人版本的關係健康感覺具強制性，社群有技術和法律權利分叉工具並在別處重建。我們拒絕建立一個單一的、全球性的「關係健康部」。透過賦權在地社群撰寫自己的評測並保留其不可剝奪的退出權，我們確保沒有任何單一行動者可以壟斷何為善的定義。

---

<h4 id="faq-14"><a href="#faq-14">Q14.</a> 威權國家正在部署 AI 進行監控、審查和軍事優勢。來自敵對來源的前沿模型攜帶有記錄的風險——資料外洩、硬編碼到訓練中的政治偏見、潛在的後門。六力談論的是關懷和社群。它對國防部、情報機構，或正在決定是否允許敵對來源模型進入其網路的政府說了什麼？</h4>

威脅是真實的，六力不予否認。防禦性回應——依據資料安全、對齊、防護健全性和開發透明度的支柱來評測模型——是必要的，而六力的原則在結構上與之相容。

在在地硬體上運行社群模型（Packs [5](../5/), [6](../6/)）是對資料外洩風險的直接防禦——社群主義對在地算力的論證，同時也是安全論證。對齊大會從根源處理政治偏見：不是換供應商，而是確保社群採用的任何模型都反映該社群的輸入。而地神架構——許多小型、有界、專用的模型——從設計上限制了後門的衝擊範圍（blast radius），同時社群撰寫的評測（[Pack 4](../4/)）提供分散式偵測，這是任何單一紅隊在規模上無法複製的。

但防禦性框架，無論多麼必要，就其自身而言是不完整的。它告訴你該排除什麼。它不告訴你該建造什麼。一個禁止敵對模型但在沒有公民治理的情況下部署國內模型的政府，處理了風險的國籍，卻保留了其結構——集中的、不受問責的智慧在個人和國家之間居中調解。

在與威權 AI 的長期競爭中，最強大的民主國家不是擁有最佳技術反制措施的國家。而是其人民最難被操弄的國家——因為經常參與搭橋對話的公民、能夠區分策展式憤怒與真實分歧的公民、透過對齊大會鍛鍊過公民肌力的公民，在結構上就能抵抗威權 AI 所賦能的影響力操作。[臺灣在 2020 年 COVID 期間僅失去七人](https://time.com/5905129/taiwan-coronavirus-record/)，且沒有任何全城封鎖——不是因為它有更好的監控，而是因為它的公民基礎設施使集體行動在無需強制的情況下成為可能。那是一種防禦能力。

六力不涵蓋武器系統或戰場自主性。那些需要各自的框架。它所涵蓋的是大多數 AI 競爭實際上將在其上進行的地形：資訊環境、公眾信任、制度韌性，以及民主社會在壓力下集體行動的能力。失去那片地形，再多的技術反制措施都不會有用。

---

<h4 id="faq-15"><a href="#faq-15">Q15.</a> 六力預設的是有界、專用的地神。如果有人還是建造了無界的超級智慧——超出框架設計範圍的系統？六力有回應，還是只是希望這件事不會發生？</h4>

它不寄望。它建造。

六力預設這種嘗試必然會發生，且不聲稱能從機器內部解決控制問題。如果一個真正無界的代理出現，沒有任何治理框架可以保證安全。問題在於它將進入什麼樣的地形。

一個圍繞單一對齊協議組織的世界——效用函數可以被顛覆、憲法可以被重新詮釋、終止開關可以被關閉——是一片單一作物的農田，對任何為它演化出的病原體都是災難性地脆弱。一個由數千個在地擁有、目的有界的地神組成的世界——每個都由擁有自己的評測、參與契約、資料主權和硬體的社群運營（Packs [2](../2/), [4](../4/), [5](../5/), [6](../6/)）——是一個生物多樣性的生態系。沒有單一的依賴可以被俘獲、沒有通用的協議可供操弄、沒有中心節點的崩潰會連鎖蔓延、沒有單一命門可供扼殺。公民韌性不需要預測病原體。它需要一個在感染到來之前就已經鍛鍊過的免疫系統。

還有更深的一點。這個問題將「無界超級智慧」視為連貫的設計目標。關懷永遠是關懷**某事物**——某條河流、某個社群、某段脈絡。一個聲稱照料整個生物圈的園丁，照料的不是任何花園。一個對一切事物進行最佳化的智慧，對任何可辨識為人類福祉的事物都不在最佳化。有界性不是六力勉強接受的局限。它是對齊本身的構成性特徵——就像「北方」在北極點上沒有意義。

無界單一主宰不是一個需要被管理的風險，而是一個需要被超越的範疇錯誤。
