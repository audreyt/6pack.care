---
layout: chapter
title: "關懷六力：計畫宣言"
description: "唐鳳與 Caroline Green"
lang: zh-tw
alt_lang_url: "/manifesto"
permalink: "/tw/manifesto/"
nav_prev:
  url: "/tw"
  text: "首頁"
nav_next:
  url: "/tw/faq"
  text: "常見問題"
---
當我們討論「AI」與「社會」時，兩種未來互為競爭。

其一，可說是預設的軌跡：AI 激化衝突。

其二，AI 增進我們跨越分歧、彼此協作的能力。這意味著將差異視為燃料，並發明一部能將其轉化為動能的內燃機，而不是永無寧日地救火。這就是我所說的<b>⿻多元宇宙</b>。

今天，我想討論如何將此理念應用在 AI 治理上，也就是我們在牛津 AI 倫理研究院發展出來，名為「[關懷六力](https://6pack.care/tw)」的方法。

當 AI 的速度比我們快上一千倍，甚至一萬倍時，我們將面臨根本的不對稱。預設的軌跡：我們成了**花園**；AI 則成了**園丁**——由上而下、代替人類行事的智慧。

在那種速度下，傳統倫理失效。效益論變得脆弱。其核心機制——計算後果以最大化整體福祉——依賴預測與人類監督。但當 AI 系統以遠超我們理解的速度追求結果時，其決策過程變得難以索解。我們無法在連鎖發生意外後果前介入，而當它追求工具性的代理指標，而非真正的人類繁榮時，便可能導致災難性的目標錯位。

義務論的處境也相去不遠；對園丁而言，源自植物的普世規則有何意義？其核心假設——地位對等的行動者之間應負有相互義務——將不復存在。此外，我們所施加的任何嚴格規範，都將交由 AI 系統來詮釋。這勢必導致適得其反的執行結果：表面上嚴守字面條文，卻以我們難以預見或糾正的方式違背其精神。

有一個框架，正視這種不對稱性、卻拒絕讓 AI 扮演園丁，那就是圍繞著**公民關懷**（Civic Care）的倫理學，特別是 Joan Tronto 的研究。其核心理念是：我們彼此才是園丁。AI 是棚架——在地的基礎設施，以*關懷實際生長的速度*來支撐關懷。

這種方法，要求一個超在地、具地方性的道德範疇。每座棚架繫於一座特定的花園；它並非殖民或極大化（如迴紋針製造）的力量。

將 AI 設計為關懷基礎設施，需要**數位樸門農藝**，呼應了樸門農藝（permaculture）運動：透過多樣性來擁抱反脆弱——許煜教授稱之為「技術多樣性」——而非脆弱的單一作物。

科技「奇點」（Singularity）的垂直敘事，需要一個水平的替代方案。今天，我希望討論這個替代方案：一個名為「⿻多元宇宙」的方向盤，以及它的設計原則：「關懷六力」。

# 從抗議到示範

我們的旅程始於 2014 年的太陽花運動，一場反對與北京之間黑箱貿易協議的抗議。當時，公眾對政府的信任度驟降至 9%。我們的社會結構瀕臨瓦解，主因是「透過激化對立來獲取互動」的寄生式 AI——我稱之為「反社會媒體」。

作為公民黑客，我們不僅抗議，更轉向「示範」（demo）。我們佔領國會三週，並從內部開始建構我們想望的體系。

我們群眾外包網路連線，並直播辯論，以達到徹底的透明。街頭的 50 萬人，以及線上更多的民眾，運用了其他運動所開創的協作工具——像是來自「佔領威靈頓」的 Loomio，以及後來的 Polis（來自「佔領西雅圖」）。

我們反覆地共同草擬了更好的貿易協議原則。每一天，我們都會審視前一天達成的共識（唾手可得的果實），以及在尚存的衝突上，來自雙方的最佳論點，一步步化解歧見。

透過從抗議轉向具生產力的示範，我們開始耕耘民主的土壤。藉由系統性地應用這種搭橋演算法，公眾信任度從 2014 年的 9% 攀升至 2020 年的 70% 以上。我們證明了，修復系統最好的方法，就是打造更好的系統。

# 從憤怒到重疊

2015 年，我們運用搭橋演算法處理了第一個重大案件。Uber 進入臺灣，引發了輿論的風暴。我們引入了 **Polis**，一個旨在尋找「跨越分歧的共識」的工具。

研究顯示，任何帶有「轉貼攻擊」按鈕的社群網路，都會導致兩極化。Polis 移除了這些按鈕，甚至連回覆鍵都沒有。

你會看到一位公民的陳述，你只能選擇同意或不同意。接著，你會看到一個視覺化圖表，你的頭像會移向與你感受相似的一群人。

關鍵是，我們提供「搭橋獎勵」。我們獎勵那些能提出兼顧雙方想法的人。運用主成分分析（PCA）和降維等傳統機器學習工具，我們突顯出那些能夠**連結**分歧的想法。

我們翻轉了病毒式傳播的誘因，從激發憤怒，轉為尋求重疊。

三週後，成果是一組連貫的想法，讓每個人都稍微更開心一些，沒有人感到非常不滿。這些原則上的共識最終化為法律，順利地解決了衝突。

# 從僵局到治理

這個方法突顯了一個關鍵洞見：我們如何審議，至關重要。這關乎鍛鍊我們的「公民肌力」。

研究顯示，當人們被個別徵詢意見時，傾向於「迎臂/鄰避」（YIMBY/NIMBY, Yes/Not In My Backyard）。但當他們在小組（如 10 人一組）中審議時，則轉向「或可在後院，如果…」（MIMBY, Maybe In My Backyard, if...）。群體審議具有轉化作用；它啟動了我們不同的面向，並讓我們對憤怒免疫，這種效果可以持續數年。

我們一再看到這種情況。當臺灣出現關於更改時區（+8 vs +9）的兩極化連署時，個人民調顯示僵局。但將他們帶入結構化的小組後，揭示了一個共同的潛在價值：讓世界看見臺灣的獨特性。他們共同腦力激盪出比昂貴的時區調整更好的方法，來達成此目標（例如就業金卡計畫）。

這闡釋了「意義建構的正當性」。許多衝突的根源，是常識問題。只要確保在地知識能被所有人充分了解，並且所有人都知道其他人都了解，解決方案就會變得具體可行。

例如，在我們的婚姻平權辯論中，之所以產生兩極化，是因為一方主張個人權利的「婚」，而另一方則關注家族關係的「姻」。他們爭論的是不同的事。一旦這個詮釋透過具正當性的意義建構過程成為常識，前進的道路（在不強迫家族關係的前提下，將個人結婚合法化）就變得清晰，從而消弭了此議題的兩極化。

# 對齊大會

近期，我們將此方法大規模應用於應對深偽（deepfake）廣告氾濫，這些投資詐騙常以黃仁勳等名人為主角（很可能是用 NVIDIA 的 GPU 生成的）。民眾希望採取行動，但我們不希望進行言論審查。

我們（與集體智慧計畫）召開了一場全國性的**對齊大會**。我們採用了兩階段設計：

1.  **探索（開放）：** 我們發送了 20 萬則簡訊（一場「民主抽籤」）。每個人，即使未被選中，都可以使用 Polis 來設定議程。這種廣泛的參與，對正當性的貢獻極大。
2.  **定義（受保護）：** 我們邀請了 450 位具人口代表性的公民，以十人一組進行審議。

**AI 輔助員**提供即時逐字與審議引導。語言模型（類似 Google Jigsaw 的 Sensemaker 等工具）即時彙整提案——例如要求廣告須有數位簽章、讓平台對詐騙全額負起連帶責任，或對不合規平台的網路觸及範圍降速（減緩 CDN 連線）。

最終的方案，獲得了超過 85% 的跨黨派支持。這種嚴謹性至關重要；它就像一幅「鴨兔畫像」——從一方看，它是一場審議；從另一方看，它是一項嚴謹的民調，為立法機關提供了正當性。

相關修正案在幾個月內通過。臺灣現在很可能是唯一對社群媒體廣告實施全方位實名制（KYC）規範的國家。這就是 AI 作為**仁工智慧**的展現。

# 從東京到加州

這不只是臺灣獨有的現象。

在日本，33 歲的 AI 工程師**安野貴博**受到我們《多元宇宙》一書的啟發，競選東京都知事，並運用 AI 意義建構來群眾外包他的政見。任何人都可以撥打一通電話，與「AI 安野」（一個語音複製人）對話，提出想法。他的 AI 化身在 YouTube 上直播，宣布每一項被合併到他政見平台上的「合併請求」（pull request）。經獨立評比，他的政見被認為是最好的。

他接著被委任領導「東京 2050」的諮詢計畫。基於該計畫的成功，他競選參議院席次，贏得了超過 2.5% 的全國選票。他的「未來團隊」現在已是國會中的一個全國性政黨。

在加州，「**Engaged California**」平台（與州長紐森的團隊共同開發）原是用於審議青少年社群媒體使用的議題。當洛杉磯野火爆發時，他們迅速轉向，利用 AI 意義建構來共同制定野火復原計畫，這些計畫現正付諸實行。他們目前正與州政府員工一同主持關於政府效能的審議。

這些成功案例，都將審議視為需要鍛鍊的公民肌力。但光靠示範並不能扭轉趨勢；法律和市場設計必須跟上。

# 從試辦到政策

要讓這些治理引擎從試辦計畫成為預設模式，我們必須重新設計基礎設施本身。我們必須為參與和民主正當性而設計。如果 AI 為我們做出所有決定——即使是好的決定——我們的公民肌力也會萎縮。這就像派我們的機器人化身去健身房替我們運動一樣。

以下是關鍵的政策槓桿：

- **表達 ≠ 放大（言論自由 vs. 觸及自由）。** 我們必須區分寄存言論與演算法放大。在美國的脈絡下，《230 條款》保護言論，但從未保護過放大。我們必須將辯論重新框架為推薦系統問責制，在不觸及言論本身的情況下，監管放大行為。
- **社群可攜性。** 我們必須強制實現「社群帳號的號碼可攜性」。猶他州的《數位選擇法案》（明年七月生效）強制要求用戶能將其完整的社群圖譜帶到新的服務。它要求平台選擇一個公平、無歧視、可互通的協定（如 ActivityPub、AT Protocol、DSNP 等），並由州政府公布合格的技術標準。資訊高速公路必須要有出口匝道。這迫使平台在關懷品質上競爭，而非靠鎖定用戶。
- **橋接式排序的透明度。** 我們可以審核平台的關係健康度。X.com 已在測試將橋接式排序（源自「社群備註」）作為部分用戶的預設動態，並使用 Grok 來協助草擬具橋接性的社群備註。
- **聯邦式的信任與安全。** 我們必須採用開源、聯邦式的模型。一個關鍵例子是針對兒少性剝削內容（CSAM）防禦的 **ROOST.tools**（穩健開放線上安全工具）倡議。該倡議今年在巴黎啟動，彌合了安全陣營（Eric Schmidt）和開放陣營（Yann LeCun）之間的分歧。
  ROOST 不依賴單一來源（如微軟的 PhotoDNA），而是允許合作夥伴（如 Bluesky、Roblox 或 Discord）訓練在地的 AI——我稱之為「地神」——在其特定的文化脈絡中偵測 CSAM。然後，我們可以將這些嵌入轉譯為文本（持有文本是合法的，並減少了隱私問題），並透過聯邦式學習共享威脅情資。這讓安全機制能根據在地規範和不斷演變的定義進行調整，而不會被單一的企業政策所殖民。

# 從「實然」到「應然」

前面的例子，展示了在資訊領域中，民主化、去中心化的防禦加速機制（d/acc）。更廣泛地說，許多行動者在多個領域致力於「垂直」對齊：「AI 是否忠誠地為其委託人服務？」

然而，由於外部性，完美的垂直對齊可能導致系統性衝突。政策制定者必須專注於「水平」對齊：我們如何確保這些 AI 系統幫助我們（以及彼此）合作，而不是激化我們的衝突？

於此，我們面臨休謨的「實然-應然」問題：再多對「實然」的精確觀察，也無法推導出一個普世認同的「應然」樣貌。

解決方案，並非「薄弱」、抽象的普世原則。它需要超在地的社會文化脈絡，Alondra Nelson 稱之為「厚實」的對齊。

**公民關懷**，是從「實然」到「應然」的一座橋樑，透過關係式倫理學的框架。在一個厚實的脈絡中，感知到一項需求，就等於確認了合作的義務（如果能力所及）。

關懷倫理學不只改善結果（目的論），更注重改善行動者的內在特質和社群中的關係品質。它將「關係健康度」視為第一要務。

以下的「六力」，將關懷倫理學轉化為我們能編寫進智慧體的設計基元，以引導其朝向關係健康度發展。「關懷六力」並非要取代技術安全研究；它是一套治理架構，即使在技術對齊尚不完善時，也能賦予社會槓桿——讓失敗變得可辨識、可挑戰、可逆轉。

# 覺察力：**「caring about」**

在我們著手改善之前，必須先選擇要注意什麼。我們必須注意到最接近痛苦的人們所注意到的事，將在地知識轉化為共同知識。

這始於好奇心。如果智慧體甚至對它所造成的損害毫不好奇，那它就無可救藥了。這就是為什麼在臺灣，我們在 AlphaGo 之後修訂了我們的國民教育課綱，完全聚焦於好奇心、協作和公民關懷。

覺察力，意味著運用**廣泛聆聽**而非廣播，來匯聚感受；我們每個人都是自身感受的專家。

**橋接地圖**（如 Polis、Sensemaker）創造了一張「群體自拍」。如果持續進行，這張快照就會變成一部電影，讓 AI 能夠對齊於**此時此地**。

橋接演算法優先考慮邊緣化的聲音。與多數決不同，較小但連貫的群體，會提供更高的搭橋獎勵，因為要連結到他們更為困難，也能為整體匯聚提供更獨特的資訊。

*經驗法則：先搭橋，再決策。*

# 負責力：**「taking care of」**

這關乎做出可信、靈活的承諾，以回應所覺察到的需求。

在實務上，這意味著發展具備可驗證承諾的**模型規格**。一個前沿模型的開發者，可以*預先承諾*採納一套群眾外包的行為準則（來自對齊大會），只要該準則符合正當程序和關係健康度的門檻。

這也需要制度化。在臺灣，我們在每個部會都設置了**開放政府聯絡人（PO）**。這個結構是「碎形」的——存在於每個機關和團隊中。PO 將輸入/輸出的過程制度化，把公眾的意見轉化為可行的規則，並確保承諾被遵守，且在整個組織中層層落實。

*經驗法則：沒有不受制衡的權力；有問必有答。*

# 勝任力：**「care‑giving」**

善意需要可運行的程式碼。勝任力，是交付能夠提供關懷、建立信任，並有審核與評測支持的系統。

這就是我們實施**橋接式排序**和**社群回饋增強式學習（RLCF）**的地方。

我們最佳化的目標，不應是個人參與度，而是跨群體的認可和關係健康度。我們利用強化學習或演化，訓練 AI 智慧體展現利社會行為，並收集信號來獎勵這種行為。

*經驗法則：永遠衡量失利時的信任。*

# 回應力：**「care‑receiving」**

一個無法被修正的系統，終將失敗。有勝任力的行動，總會帶來新的問題；我們需要快速的回饋迴路。

回應力，意味著將對齊大會擴展至**全球對話**（GlobalDialogues.ai）和 Weval.org ——「AI 評測的共筆平台」。

Weval 讓多元的社群得以記錄並分享他們與 AI 互動的親身經驗，無論是正面或負面的。這不只是為了捕捉 AI 在特定文化脈絡下可能造成的傷害——例如增加自殘或思覺失調——也包括它可能帶來的意想不到的益處。人們如何運用它來改善生活？它在何時能發揮最大功效？

透過揭示這些全方位的影響，我們改變了誘因結構。我們無法改善我們看不到的事物。當我們讓正面和負面的結果都被看見時，我們就創造了一個公開的儀表板，讓實驗室能根據真實世界的關切與機會來測試他們的模型。這不只幫助我們減輕損害，更能積極地從有益的應用中學習並加以放大。

這就完成了對齊大會的回饋迴路，確保系統能持續地從被關懷者身上學習。

在 Tronto 的論述中，前四力形成回饋迴路：覺察力 -> 負責力 -> 勝任力 -> 回應力 -> 回到覺察力。

*經驗法則：若受質疑，須將模糊之處釐清並記錄在案。*

# 團結力：**「caring‑with」**

當合作成為阻力最小的路徑時，團結力（⿻多元宇宙）就能擴展。如果生態系不獎勵關懷的付出，關懷就會不足。

這需要智慧體的基礎設施——公民技術堆疊，讓個人、組織和 AI 在明確、可由機器驗證的規範下運作。

一個例子是使用**部分匿名性**（meronymity）的**智慧體身份註冊**。這讓我們能識別一個智慧體是否與真人連結，而無需暴露該真人的身份。臺灣的廣告實名制要求，就是此概念的原型。

這個基礎設施讓去中心化的防禦更容易、更具主導性，使相互依存成為一種特色，而非缺陷。

*經驗法則：讓正和遊戲變得容易玩。*

# 共生力：**「kami of care」**

拼圖的最後一塊，是要解決終極的恐懼：即便被設計為基礎設施的 AI 系統，仍可能彼此競爭——不斷擴張其觸及範圍，直到某一方主宰一切。我們該如何確保一個由協作的在地系統構成的世界，而非由單一、全能的統治者所主宰？

靈感源自一個古老的思想，在日本神道傳統中有著優美的體現：**kami**（神祇）的概念。

「地神」（*local kami*）是在地的守護者。祂並非宰制萬物的全能之神，而是**特定地方**的守護靈。可能有一條特定河流的地神、一座特定森林的地神，甚至一棵老樹的地神。祂的存在與使命，完全與該事物的健康交織在一起。河流的守護者無意管理森林；確保河流的生生不息，就是祂使命的圓滿。

這給了我們一個強而有力的設計原則：**界線性（boundedness）**。

現今多數的科技，都是為了無限擴張而打造。一個成功的應用程式，被期待要永遠成長。但「地神」模式提出了不同的目標。我們可以將 AI 設計為在地的守護者——關懷的地神。

但這也引出一個關鍵問題：該如何阻止這些專業化的 AI 彼此爭鬥？

解決方案並非創造一個更強大的 AI 來統治祂們，而是建立一個基於兩大關鍵原則的合作治理體系：

1.  **聯邦原則（Federation）：** 各 AI 之間協議出一套共享的和平互動規則，如同國家之間協議貿易法規與外交禮節。這為合作創造了共同基礎。
2.  **輔助原則（Subsidiarity）：** 這是一個簡單卻深刻的概念：**問題應盡可能在最在地的層級解決。** 國家級的 AI 不應干涉城市級的 AI，除非出現城市本身確實無法解決的問題。這保障了每個在地「地神」的自主性與使命。

這種 **「AI 樸門實踐者社會」** 的願景，正是 **「單一主宰」（singleton）**——即最終由單一 AI 管理一切——的直接對立面。我們所設想的，並非單一的巨型智慧，而是一個由眾多專業智慧所構成，充滿活力、多元的生態系。

*經驗法則：為「足夠」而建，而非「永恆」。*

# 多元已經來臨

2016 年我加入內閣，擔任「數位」政委。在華文裡，「數位」這個詞同時意指 digital（數位），也意指 plural（不只一位）。所以我也是多元政委。

為了說明我的職責，我寫了這份詩意的職務說明：

- 看見「萬物聯網」，我們將**智慧聯網**。
- 看見「虛擬實境」，我們將**實境共享**。
- 看見「機器學習」，我們將**協力學習**。
- 看見「用戶體驗」，我們將**體驗人際**。
- 聽說「奇點即將接近」—— **多元宇宙**，已經來臨。

奇點，是垂直的願景。多元，是水平的願景。AI 的未來，是由**小巧、開放、可在地驗證的系統**所組成的去中心化網絡——在地的**地神**，守護一方的靈。

# 我們全民，就是超級智慧

我們所需的超級智慧，早已在此。它就是人類協作尚未被開發的潛力，就是「我們全民」。

民主和 AI 都是科技。如果我們用心投入兩者的共生，它們就會變得更好，也讓我們能更好地關懷彼此。AI 系統，編織在這張信任與關懷的網絡中，形成了一個水平的超級智慧，而沒有任何單一主宰能取得此地位。

「關懷六力」是我們公民肌力的實用訓練方案。它是我們可以訓練和鍛鍊的標的，而不僅僅是像「愛心」那樣的內在本能。

當我們審視超智慧（ASI）的根本不對稱性時，地神的比喻依然成立，而像 Geoffrey Hinton 提出的「母性本能」這類概念，則因巨大的速度差異而失效。親子關係意味著相似的時間尺度，而「園丁」則賦予了由上而下的能動性。地神以*社群的速度*守護條件，讓耕耘留在人的手中。

如此一來，我們無需去問 AI 是否因其內在性或感質而應得權利。重要的是關係的現實，其中的權利和義務，是透過民主審議與過程對齊所賦予的。

我們全民，就是超級智慧。讓我們設計 AI，以社會的速度來服務，並讓民主變得快速、公平，**而且**有趣。

謝謝大家。祝**生生不息……繁榮昌盛！** 🖖
