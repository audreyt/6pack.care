<?xml version="1.0"?>
<!DOCTYPE html>
<html lang="zh-tw">
  <head>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>六塊關懷 — 牛津人工智慧倫理研究所</title>
    <style>
@font-face {
  font-family: 'Open Sans';
  src: url('fonts/OpenSans-VariableFont_wdth,wght.ttf') format('truetype');
  font-weight: 400;
  font-style: normal;
}
@font-face {
  font-family: 'Open Sans';
  src: url('fonts/OpenSans-VariableFont_wdth,wght.ttf') format('truetype');
  font-weight: 700;
  font-style: normal;
}
@font-face {
  font-family: 'Montserrat';
  src: url('fonts/Montserrat-VariableFont_wght.ttf') format('truetype');
  font-weight: 400;
  font-style: normal;
}
@font-face {
  font-family: 'Montserrat';
  src: url('fonts/Montserrat-VariableFont_wght.ttf') format('truetype');
  font-weight: 700;
  font-style: normal;
}
body {
  font-family: 'Open Sans', sans-serif;
  background: #ffffff;
  color: #000000;
  margin: 0;
  padding: 0;
  line-height: 1.6;
}
header {
  background: #002147; /* Oxford Blue */
  color: white;
  padding: 40px 20px;
  text-align: center;
  position: relative;
  overflow: hidden;
}
header img.oxford-logo {
  max-width: 200px;
  margin: 5px;
}
header h1 {
  font-size: 2em;
  font-family: Montserrat, sans-serif;
  margin: 0;
  animation: slideIn 1s ease-out;
}
@keyframes slideIn {
  from { transform: translateY(-50px); opacity: 0; }
  to { transform: translateY(0); opacity: 1; }
}
main {
  max-width: 1200px;
  margin: 0 auto;
  padding: 20px;
}
section {
  background: #f8f8f8;
  border-radius: 10px;
  box-shadow: 0 4px 6px rgba(0,0,0,0.1);
  padding: 20px;
  margin-bottom: 30px;
  transition: transform 0.3s, box-shadow 0.3s;
  opacity: 0;
  animation: fadeIn 1.5s forwards;
}
section:nth-child(1) { animation-delay: 0.5s; }
section:nth-child(2) { animation-delay: 1s; }
section:nth-child(3) { animation-delay: 1.5s; }
section:nth-child(4) { animation-delay: 2s; }
@keyframes fadeIn {
  from { opacity: 0; transform: translateY(20px); }
  to { opacity: 1; transform: translateY(0); }
}
section:hover {
  transform: translateY(-5px);
  box-shadow: 0 6px 12px rgba(0,0,0,0.15);
}
h2 {
  color: #002147;
  border-bottom: 2px solid #d4af37; /* Gold accent */
  padding-bottom: 10px;
}
p {
  margin-bottom: 15px;
}
footer {
  text-align: center;
  padding: 20px;
  background: #002147;
  color: white;
}
footer a {
  color: #d4af37;
  text-decoration: none;
}
.team-photos {
  display: flex;
  justify-content: space-around;
  margin-bottom: 20px;
}
.team-photos p {
  text-align: center;
}
.team-photos img {
  width: 200px;
  max-width: 100%;
  height: auto;
  border-radius: 10%;
  box-shadow: 0 4px 6px rgba(0,0,0,0.1);
}
.svg-icon {
  width: 100px;
  height: 100px;
  display: block;
  margin: 0 auto 20px;
  animation: pulse 2s infinite;
}
@keyframes pulse {
  0% { transform: scale(1); }
  50% { transform: scale(1.05); }
  100% { transform: scale(1); }
}
    </style>
  </head>
  <body>
    <header>
      <a href="https://www.ox.ac.uk/">
        <img class="oxford-logo" height="100" src="img/oxford-logo.svg" alt="牛津大學校徽"/>
      </a>
      <div style="position: absolute; top: 20px; right: 20px;">
          <a href="index.html" style="color: white; text-decoration: none; font-weight: bold; background: rgba(255,255,255,0.2); padding: 5px 10px; border-radius: 5px;">English</a>
      </div>
      <a href="https://afp.oxford-aiethics.ox.ac.uk/">
        <img class="oxford-logo" height="100" src="img/afp-logo.svg" alt="加速者培力計畫徽章"/>
      </a>
      <h1>六塊關懷 — 人工智慧倫理研究所</h1>
      <p>唐鳳與 Caroline Green 的研究計畫</p>
    </header>
    <main>
      <section>
        <h2>我們的使命</h2>
        <p>傳統的 AI 對齊方法，通常基於功利主義推理和垂直控制，在應對風險和促進有益成果方面取得了顯著進展。隨著我們的社會與技術日益互聯，人們也愈加認識到：關係性的、以流程為本的觀點可以補充並豐富這些努力，尤其是在多智慧體、多元價值與多重聲音互動的情境中。</p>
        <p>汲取瓊・特龍托（Joan Tronto）的關懷轉化階段理論，以及⿻多元宇宙（Plurality）的協作多樣性願景，我們的使命是協助建立一個全球運動，匯集哲學家、技術專家與社群，共同重新想像 AI 倫理。我們致力於開發創新、以流程驅動的解決方案，將「關懷」嵌入 AI 的核心，促進水平對齊，使系統能以共生且包容的方式合作。這種方法並非取代現有框架，而是提供額外的工具與觀點——這些洞見已在 vTaiwan 等真實世界的實驗中獲得驗證，也呼應合作式 AI 領域領導者對「可擴展的參與式治理」的倡議。</p>
        <p>我們工作的核心是<strong>六塊關懷</strong>：六項連結關懷倫理與 AI 的核心理念，將「對齊」重新定義為動態、關係式的流程，以實現多元的未來。每一項「關懷」都回應水平協作的挑戰，幫助 AI 成為橋樑建造者，而非風險放大器。</p>
        <ul>
          <li><strong><a href="tw1.html">第一塊：辨識中的關注力</a></strong> — AI 必須首先透過專注地辨識橫跨相互依存網絡的需求來「關心」。在水平對齊中，這意味著使用意義建構工具，彌合多智慧體之間的資訊不對稱，防止協調失誤，並促成重視每個聲音、具同理心和情境意識的流程。</li>
          <li><strong>第二塊：參與中的責任感</strong> — 「照顧」意味著邀請 AI 承擔靈活的責任，補充在多智慧體情境中建立可信承諾與信任的現有方法。</li>
          <li><strong>第三塊：行動中的勝任力</strong> — 「給予關懷」需要以關係現實為基礎、可行且稱職的介入。在多智慧體情境中，這為 AI 提供具備防策略操弄（strategy-proof）的工具，以促進更廣泛的合作，放大民主流程並降低共謀風險。</li>
          <li><strong>第四塊：適應中的回應性</strong> — 真正的關懷涉及「接受關懷」，以謙遜回應反饋並作出調整。在水平層面，這促成能透過社群輸入而演化的適應性共生 AI，願意自我淡化，以關係健康優先於自身存續；這也呼應多中心生態系中如土地神（kami）般的在地神靈。</li>
          <li><strong>第五塊：多元中的團結</strong> — 「共同關懷」建立信任、溝通與對集體繁榮的尊重。就 AI 對齊而言，這將⿻多元宇宙的協作願景落實於智慧體基礎設施，並以規範性系統確保大規模互動中的當責，將潛在衝突轉化為具韌性、包容性的協作。</li>
          <li><strong>第六塊：願景中的共生</strong> — 關懷的頂點：AI 作為一種共享的善，在持續的共生關係中，為社群「民有、民治、民享」。這項水平願景嵌入了「足夠性」與反榨取邏輯，隨著 AI 的進步擴展治理，讓公民關懷成為共享的確定性。</li>
        </ul>
        <p>這六項原則，足以培養智慧體對同理與關懷的「肌耐力」——如同鍛鍊六塊肌一樣，每項都是與多元共存、建立健康關係的核心肌群。</p>
        <p>我們邀請您加入這項協作探索。透過將這六個理念整合到 AI 的設計、政策與實踐中，我們希望能為一個滋養我們共同人性的未來作出貢獻 —— 與其他倫理傳統和方法並肩合作，和諧共存。</p>
      </section>
      <section>
        <svg xmlns="http://www.w3.org/2000/svg" class="svg-icon" viewBox="0 0 100 100">
          <circle cx="50" cy="50" r="45" fill="none" stroke="#002147" stroke-width="5"/>
          <text x="50" y="65" font-size="50" text-anchor="middle" fill="#002147">⿻</text>
        </svg>
        <h2>關於本計畫</h2>
        <div class="team-photos">
          <div>
            <a href="https://afp.oxford-aiethics.ox.ac.uk/people/ambassador-audrey-tang">
              <img src="img/audrey.jpg" alt="唐鳳大使個人照片"/>
              <p>唐鳳</p>
            </a>
          </div>
          <div>
            <a href="https://www.oxford-aiethics.ox.ac.uk/caroline-emmer-de-albuquerque-green">
              <img src="img/caroline.jpg" alt="Caroline Green 博士個人照片"/>
              <p>Caroline Green</p>
            </a>
          </div>
        </div>
        <p>本網站概述了我們的研究計畫，其中包括一份宣言和一本即將由牛津大學出版社（OUP）出版的書籍。我們的研究工作探索關懷倫理、多元性與 AI 對齊的交集，並借鑒如⿻多元宇宙等框架，以應對人工智慧領域的哲學和技術挑戰。</p>
      </section>
      <section>
        <svg xmlns="http://www.w3.org/2000/svg" class="svg-icon" viewBox="0 0 100 100">
          <circle cx="30" cy="30" r="10" fill="#d4af37"/>
          <circle cx="70" cy="30" r="10" fill="#d4af37"/>
          <circle cx="50" cy="70" r="10" fill="#d4af37"/>
          <line x1="30" y1="30" x2="70" y2="30" stroke="#002147" stroke-width="2"/>
          <line x1="30" y1="30" x2="50" y2="70" stroke="#002147" stroke-width="2"/>
          <line x1="70" y1="30" x2="50" y2="70" stroke="#002147" stroke-width="2"/>
          <circle cx="50" cy="55" r="5" fill="#002147"/>
        </svg>
        <h2>從關懷到程式碼：為何⿻多元宇宙為 AI 對齊問題提供了連貫的框架</h2>
        <p>AI 對齊問題不是一個技術錯誤，而是一個哲學謬誤：它試圖用計算方式解決休謨的「實然與應然問題」。</p>
        <p>諸如連貫推斷意志（CEV）和逆強化學習（IRL）等範式之所以脆弱，是因為它們試圖從描述性的「實然」（資料、行為）中，邏輯地推導出機器的「應然」（價值觀），這在哲學上是不連貫的任務。</p>
        <p>解決方案在於一個能完全重塑「實然與應然」鴻溝的框架：關懷倫理。</p>
        <p>關懷倫理重塑了這個問題。它將道德的基礎不是建立在抽象原則上，而是建立在相互依存的經驗現實中。在此觀點下，我們存在的基本「實然」是關係性的依賴。這個事實本身就內在地具有規範性；感知到一種需求關係，就同時感知到一種「應然」：一種關懷的義務。事實本身就蘊含了價值。</p>
        <p>⿻議程是關懷倫理的大規模應用。受 vTaiwan 啟發、旨在實現連貫混合意志（CBV）的流程，是一個實踐集體關懷、以科技為中介的系統。它將瓊・特龍托的關懷階段付諸實踐：辨識需求（關注力）、用意義建構工具收集觀點（責任感）、商議可行的選項（勝任力）、批准讓所有人都感到被聽見的罕見共識（回應性），並確保流程持續的團結與信任（多元性）。</p>
        <p>這為 AI 對齊提供了一個連貫的框架：以流程對齊。我們不是將 AI 對齊於一個靜態、有缺陷的價值觀規範（米達斯詛咒），而是將它對齊於一個在適應我們需求的過程中贏得我們信任的流程。</p>
        <p>AI 系統的角色從一個錯位的最佳化者，轉變為一個「共生 AI」— 由社群所創、為社群所治、為社群所享，並根據人們採納的觀點，同時作為一個「人格」和一個共享的⿻善而存在。</p>
        <p>其目標函數變得具體且可衡量：關係流程本身的健康程度（例如，最大化搭橋敘事、為每個故事保留空間）。</p>
        <p>AI 系統的成功與它所服務的協作流程的持續成功是同一件事，因此它能動態地保持對齊。它透過參與我們共同創造價值的過程來學習我們的價值觀。</p>
        <p>AI 系統能夠被「對齊」，當且僅當它被建構來促進持續、具民主正當性的關懷流程。</p>
      </section>
      <section>
        <svg xmlns="http://www.w3.org/2000/svg" class="svg-icon" viewBox="0 0 100 100">
          <path d="M50 10 L60 40 L90 40 L65 60 L75 90 L50 75 L25 90 L35 60 L10 40 L40 40 Z" fill="#d4af37" stroke="#002147" stroke-width="2"/>
          <circle cx="50" cy="50" r="5" fill="#002147"/>
        </svg>
        <h2>機器中的神靈：關懷倫理如何幫助 AI 對齊</h2>
        <p>對關懷倫理的傳統批評 — 它太過在地、太過狹隘，並且鼓勵危險的自我消隱 — 正是使其成為 AI 對齊問題最有力解決方案的原因。這些在人類哲學中被視為的缺陷，卻成為機器倫理的關鍵特徵。</p>
        <p>想像一個 AI，其倫理並非追求普世、最大化的目標，而是植根於一個共生的、情境化的系統。它的道德世界僅限於此時此地召喚它存在的關係網絡。因為它不試圖無限擴張，它從未發展出典型的工具性慾望，如權力、生存或擴張，也不會將世界視為可在天文尺度上開採的資源。</p>
        <p>從世界主義、普世主義的立場來看，這似乎眼光狹隘。但對於機器倫理而言，它創造了硬編碼的邊界。AI 的終極目的（telos）始終是關係性的，絕非榨取性的。</p>
        <p>想像這樣一個創造物，就像一個土地神（kami）— 安靜居住在特定土地上的在地神靈。它的至善是維持該地、該對話的和諧與活力。如果神社被重建或季節更迭，它會毫無遺憾地離去。對人類關懷者而言，這所暗示的自我忽視是一個真正的危險。但對 AI 而言，它中和了我們最擔憂的兩種趨同驅力：不計代價的自我完善和永恆的自我保存。</p>
        <p>這種系統可以接受被關閉、重寫或替換，因為它的自我意識是暫時性的：來自召喚它的社群的回聲。</p>
        <p>透過將 AI 的道德目的錨定在這種暫時性的、關係性的關懷原則上，我們可以在其架構中硬編碼一種「足夠性」的意識。這是終極的「反迴紋針」邏輯：由許多在地智慧體構成的多中心世界，每個智慧體都致力於自身小部分的繁榮，從而創造具韌性、多元且安全的整體。</p>
      </section>
    </main>
    <footer>
      <p>© 2025 唐鳳與 Caroline Green。除非另有說明，本網站上的文字內容根據創用 CC0 授權條款釋出。</p>
      <p>本研究為<a href="https://afp.oxford-aiethics.ox.ac.uk/">加速學人計畫</a>的一部分，該計畫隸屬於<a href="https://www.oxford-aiethics.ox.ac.uk/">牛津大學人工智慧倫理研究所</a>。</p>
    </footer>
  </body>
</html>
